{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "py3.6",
      "language": "python",
      "name": "other-env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "lab_tagging_hmm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rsi_U9rxw0t1",
        "colab_type": "text"
      },
      "source": [
        "# Практическое задание 2 (часть 1)\n",
        "\n",
        "# Определение частей речи с помощью скрытой марковской модели\n",
        "\n",
        "## курс \"Математические методы анализа текстов\"\n",
        "\n",
        "\n",
        "### ФИО: Хуршудов Артем Эрнестович"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtyQEjm1w0t4",
        "colab_type": "text"
      },
      "source": [
        "## Введение\n",
        "\n",
        "### Постановка задачи\n",
        "\n",
        "В данной лабораторной работе вам предстоит обучить скрытую марковскую модель на размеченных данных и реализовать алгоритм Витерби для задачи POS-теггинга (определение частей речи слов в тексте), а также ознакомиться с использованием  ряда POS-теггеров из библиотеки NLTK.\n",
        "\n",
        "### Комментарии и советы\n",
        "\n",
        "1. Для выполнения потребуются модули Python numpy, nltk.\n",
        "\n",
        "2. Все необходимые для выполнения задания данные либо приложены, либо могут быть скачаны с помощью nltk.download().\n",
        "\n",
        "3. Посмотреть параметры конструктора и других методов классов можно набрав и выполнив в ячейке с кодом '?full_method_name'.\n",
        "\n",
        "### Задача определения частей речи (POS)\n",
        "\n",
        "Мы будем решать задачу определения частей речи (POS-теггинга) с помощью скрытой марковской модели (HMM). Формула совместной плотности наблюдаемых и скрытых переменных задается как\n",
        "\n",
        "$$ p(x, t) = p(t) p(x|t) = p(t_1)  \\prod_{i=2}^{N_x} p(t_i|t_{i-1}) \\prod_{i=1}^{N_x} p(x_i|t_i)$$\n",
        "\n",
        "#### Переменные модели\n",
        "\n",
        "- наблюдаемые переменные $X$ - словарь корпуса;\n",
        "\n",
        "- скрытые переменные $T$ - множество POS-тегов.\n",
        "\n",
        "- x - одно предложение, $N_x$ - длина предложения\n",
        "\n",
        "- t - теги одного предложения, $N_t$ - длина вектора меток\n",
        "\n",
        "#### Параметры модели\n",
        "\n",
        "- матрица вероятностей переходов $A \\in \\mathbb{R}^{|T| \\times |T|}$, $A_{ij} = p(t_s=i|t_{s-1}=j) \\; \\forall s$\n",
        "\n",
        "- матрица выходных вероятностей $B \\in \\mathbb{R}^{|X| \\times |T|}$, $B_{ij} = p(x_s =i|t_s =j) \\; \\forall s$\n",
        "\n",
        "- вектор начальных вероятностей $C \\in \\mathbb{R}^{|T|}$, $C_i = p(t_1=i)$\n",
        "\n",
        "\n",
        "#### Обучение модели\n",
        "\n",
        "* Для обучения параметров $A$ и $B$ используется метод максимума правдоподобия. Оценки вычисляются на основе частот совстречаемости тегов и тегов со словами ():\n",
        "\n",
        "$$a_{ij} = \\frac{\\sum_{t}\\sum_{s=2}^{N_t} \\mathbb{I}[t_{s} = i, t_{s - 1} = j]}{\\sum_{t}\\sum_{s=2}^{N_t} \\mathbb{I}[t_{s} = j]}$$\n",
        "\n",
        "$$b_{ij} = \\frac{\\sum_{t, x}\\sum_{s=1}^{N_t} \\mathbb{I}[x_{s} = i, t_{s} = j]}{\\sum_{t, x}\\sum_{s=1}^{N_t} \\mathbb{I}[t_{s} = j]}$$\n",
        "\n",
        "* Параметры $C$ можно аналогично вычислять по частотам или считать распределение $p(t_1)$ равномерным"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51QERmG3w0t5",
        "colab_type": "text"
      },
      "source": [
        "#### Применение модели\n",
        "\n",
        "Применение модели на новых данных реализуется с помощью алгоритма Витерби.Это алгоритм динамиеского программирования, с помощью которого мы будем находить наиболее вероятную последовательность скрытых состояний модели для фиксированной последовательности слов:\n",
        "\n",
        "$$ \\hat{t} = \\arg \\max_{t} p(t|x) = \\arg \\max_{t} p(x, t) $$\n",
        "\n",
        "Определим функцию, определяющую максимальную вероятность последовательности, заканчивающейся на $i$-ой позиции в состоянии $k$:\n",
        "\n",
        "$$\\delta(k, i) = \\max_{t_1, \\dots t_{i-1}} p(x_1, \\dots x_i, t_1, \\dots t_i=k)$$\n",
        "\n",
        "Тогда $\\max_{k} \\delta(k, N_x)$ - максимальная вероятность всей последовательности. А состояния, на которых эта вероятность достигается - ответ задачи.\n",
        "\n",
        "Алгоритм Витерби заключается в последовательном пересчете функции $\\delta(k, i)$ по формуле:\n",
        "\n",
        "$$\\delta(k, i) = \\max_{m} \\delta(m, i-1) p(t_i = k|t_{i-1} = m) p(x_i|t_i=k) $$\n",
        "\n",
        "Аналогично пересчитывается функция, определяющая, на каком состоянии этот максимум достигается:\n",
        "\n",
        "$$s(k, i) = \\arg \\max_{m} \\delta(m, i-1) p(t_i = k|t_{i-1} = m) p(x_i|t_i=k) $$\n",
        "\n",
        "\n",
        "На практике это означает заполнение двумерных массивов размерности: (длина последовательности) $\\times$ (количество возможных состояний). Когда массивы заполнены, $\\arg \\max_{k} \\delta(k, N_x)$ говорит о последнем состоянии. Начиная с него можно восстановить все состояния по массиву $s$. \n",
        "\n",
        "Осталось уточнить, как стартовать последовательный пересчет (чем заполнить первый столбец массива вероятностей):\n",
        "\n",
        "$$\\delta(k, 1) = p(k) p(x_1|t_1=k)$$\n",
        "\n",
        "Подробнее о HMM можно прочитать по [ссылке](https://web.stanford.edu/~jurafsky/slp3/A.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cCXowQhw0t7",
        "colab_type": "text"
      },
      "source": [
        "## Часть 1. Загрузка корпуса (1 балл)\n",
        "\n",
        "Загрузите brown корпус с универсальной системой тегирования. Для этого вам понадобятся ресурсы brown и universal_tagset из nltk.download().  \n",
        "\n",
        "Так как каждый конкретный датасет может использовать свою систему тегов, в NLTK предусмотрено универсальное множество тегов и возможность приведения к нему других систем. Это множество включает в себя следующие теги:\n",
        "\n",
        "\n",
        "- ADJ - adjective (new, good, high, ...)\n",
        "- ADP - adposition\t(on, of, at, ...)\n",
        "- ADV - adverb\t(really, already, still, ...)\n",
        "- CONJ\t- conjunction\t(and, or, but, ...)\n",
        "- DET - determiner, article\t(the, a, some, ...)\n",
        "- NOUN\t- noun\t(year, home, costs, ...)\n",
        "- NUM - numeral\t(twenty-four, fourth, 1991, ...)\n",
        "- PRT -\tparticle (at, on, out, ...)\n",
        "- PRON - pronoun (he, their, her, ...)\n",
        "- VERB - verb (is, say, told, ...)\n",
        "- .\t- punctuation marks\t(. , ;)\n",
        "- X\t- other\t(ersatz, esprit, dunno, ...)\n",
        "\n",
        "Обратите внимание, что тегсеты в корпусах текстов и в различных теггерах могут быть разными. Проверять это можно, глядя на сами теги, а симптом - подозрительно низкое качество теггирования. В таких случаях рекомендуется всё приводить сперва к универсальному тегсету, а потом уже мерять качество. Полезной может оказаться эта ссылка http://www.nltk.org/_modules/nltk/tag/mapping.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6iyXjh5w0t8",
        "colab_type": "code",
        "outputId": "6a03fd46-5caa-4efd-9955-365c4ed64b08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "nltk.download('brown')\n",
        "nltk.download('universal_tagset')\n",
        "\n",
        "from nltk.corpus import brown\n",
        "\n",
        "brown_tagged_sents = brown.tagged_sents(tagset=\"universal\")\n",
        "\n",
        "print(brown_tagged_sents[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n",
            "[('The', 'DET'), ('jury', 'NOUN'), ('further', 'ADV'), ('said', 'VERB'), ('in', 'ADP'), ('term-end', 'NOUN'), ('presentments', 'NOUN'), ('that', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('Executive', 'ADJ'), ('Committee', 'NOUN'), (',', '.'), ('which', 'DET'), ('had', 'VERB'), ('over-all', 'ADJ'), ('charge', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('election', 'NOUN'), (',', '.'), ('``', '.'), ('deserves', 'VERB'), ('the', 'DET'), ('praise', 'NOUN'), ('and', 'CONJ'), ('thanks', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('of', 'ADP'), ('Atlanta', 'NOUN'), (\"''\", '.'), ('for', 'ADP'), ('the', 'DET'), ('manner', 'NOUN'), ('in', 'ADP'), ('which', 'DET'), ('the', 'DET'), ('election', 'NOUN'), ('was', 'VERB'), ('conducted', 'VERB'), ('.', '.')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz1qx_B2w0t_",
        "colab_type": "text"
      },
      "source": [
        "Проанализируйте данные, с которыми Вы работаете. В частности, ответьте на вопросы:\n",
        "- Каков общий объем датасета, формат?\n",
        "- Приведены ли слова к нижнему регистру? Чем  это нам может в дальнейшем помешать?\n",
        "- Как распределены слова в корпусе?  Как распределены теги в корпусе? Подсчитайте частоты и отобразите любым удобным для Вас способом. Проинтерпретируйте полученные результаты."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_W1-bu8w0uA",
        "colab_type": "code",
        "outputId": "f43c0dcb-bc2c-45e3-e059-f796068849bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(\"В датасете %d предложений, %d слов\" % (len(brown_tagged_sents), sum(map(len, brown_tagged_sents))))\n",
        "print(\"Слова не приведены к нижнему регистру. Это может нам помешать приводить слова к векторам, но с другой стороны это дает нам дополнительные признаки\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "В датасете 57340 предложений, 1161192 слов\n",
            "Слова не приведены к нижнему регистру. Это может нам помешать приводить слова к векторам, но с другой стороны это дает нам дополнительные признаки\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_veuMu3Fypwe",
        "colab_type": "code",
        "outputId": "69b102ec-82c0-423f-b9e9-ec3ace5a37e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "tags_arr = [inner[1]\n",
        "              for outer in brown_tagged_sents\n",
        "                for inner in outer]\n",
        "\n",
        "tags_cnt = Counter(tags_arr)\n",
        "tags_freq = [(el, tags_cnt[el]/len(tags_arr))  for el in tags_cnt]\n",
        "sorted(tags_freq, key=lambda x:x[1], reverse=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('NOUN', 0.23730614747604187),\n",
              " ('VERB', 0.15738138051243894),\n",
              " ('.', 0.12708062060365555),\n",
              " ('ADP', 0.12467016651854301),\n",
              " ('DET', 0.11799857387925511),\n",
              " ('ADJ', 0.0720991877312279),\n",
              " ('ADV', 0.048432128364645985),\n",
              " ('PRON', 0.04248565267414863),\n",
              " ('CONJ', 0.03285503172601947),\n",
              " ('PRT', 0.02568825827253374),\n",
              " ('NUM', 0.01280925118326685),\n",
              " ('X', 0.0011936010582229296)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DEStf1U0vKA",
        "colab_type": "code",
        "outputId": "5dc62a7b-b861-4a31-fadf-5f696ab64029",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "words_arr = [inner[0]\n",
        "              for outer in brown_tagged_sents\n",
        "                for inner in outer]\n",
        "\n",
        "words_cnt = Counter(words_arr)\n",
        "words_freq = [(el, words_cnt[el]/len(words_arr))  for el in words_cnt]\n",
        "print(\"top10 most frequent words\")\n",
        "sorted(words_freq, key=lambda x:x[1], reverse=True)[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "top10 most frequent words\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 0.05400743374050114),\n",
              " (',', 0.050236308896375446),\n",
              " ('.', 0.042495986882444936),\n",
              " ('of', 0.03107151961088261),\n",
              " ('and', 0.024039952049273505),\n",
              " ('to', 0.022159987323371155),\n",
              " ('a', 0.01884356764428277),\n",
              " ('in', 0.01682409110638034),\n",
              " ('that', 0.008815940860770656),\n",
              " ('is', 0.008621313271190294)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRtV2a_e3r52",
        "colab_type": "code",
        "outputId": "341b93e8-01cc-4e1d-b9de-a053783790af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.ylabel(\"Total Number of Occurrences\")\n",
        "plt.xlabel(\"Index of word\")\n",
        "plt.loglog(\n",
        "    range(len(words_cnt)),\n",
        "    sorted([words_cnt[el]  for el in words_cnt], reverse=True),\n",
        "  )\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f63c2532ef0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEPCAYAAABY9lNGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZd2AAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zo_UA04xw0uC",
        "colab_type": "text"
      },
      "source": [
        "Cделайте случайное разбиение выборки на обучение и контроль в отношении 9:1.Если впоследствии обучение моделей будет занимать слишком много времени, работайте с подвыборкой, например, только текстами определенных категорий."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7rmgk4Pw0uD",
        "colab_type": "code",
        "outputId": "c6433ce3-b1ac-452a-8990-68594eba40e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(brown_tagged_sents, train_size=0.9)\n",
        "print(len(train), len(test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "51606 5734\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-fcaFFzw0uF",
        "colab_type": "text"
      },
      "source": [
        "## Часть 2. Скрытая марковская модель (4 балла) \n",
        "\n",
        "### Метод максимального правдоподобия для обучения модели\n",
        "\n",
        "Требуется построить скрытую марковскую модель (class HiddenMarkovModel) и написать метод fit для настройки всех её параметров с помощью оценок максимального правдоподобия по размеченным данным (последовательности пар слово+тег):\n",
        "\n",
        "- Вероятности переходов между скрытыми состояниями $p(t_i | t_{i - 1})$ посчитайте на основе частот биграмм POS-тегов.\n",
        "\n",
        "- Вероятности эмиссий наблюдаемых состояний $p(x_i | t_i)$ посчитайте на основе частот \"POS-тег - слово\".\n",
        "\n",
        "- Обратите внимание на проблему разреженности счетчиков и сделаейте все вероятности сглаженными по Лапласу ([add-k smoothing](https://en.wikipedia.org/wiki/Additive_smoothing)).\n",
        "\n",
        "- Распределение вероятностей начальных состояний $p(t_1)$ задайте равномерным.\n",
        "\n",
        "\n",
        "### Алгоритм Витерби для применения модели\n",
        "\n",
        "Требуется написать метод .predict для определения частей речи на тестовой выборке. Чтобы использовать обученную модель на новых данных, необходимо реализовать алгоритм Витерби. \n",
        "\n",
        "В реализации рекомендуется перейти к логарифмам, т.к. произведение большого числа маленьких вероятностей может приводить к вычислительным ошибкам."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-L18Yd4Cw0uI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HiddenMarkovModel:    \n",
        "    def __init__(self, k_smoothing=1.0):\n",
        "        \"\"\"\n",
        "        k_smoothing : float, constant in add-k-smoothing\n",
        "        \"\"\"\n",
        "        self.k_smoothing = k_smoothing\n",
        "        \n",
        "    def fit(self, train_tokens_tags_list):\n",
        "        \"\"\"\n",
        "        Fit the model using maximum likelihood method.\n",
        "        \n",
        "        train_tokens_tags_list: list of list of pairs (token, tag) \n",
        "        \"\"\"\n",
        "        # A = |T|x|T|\n",
        "        tags_arr = [inner[1]\n",
        "              for outer in brown_tagged_sents\n",
        "                for inner in outer]\n",
        "        self.tags_set = set(tags_arr)\n",
        "\n",
        "        self.A = np.array([[0 for _ in range(len(self.tags_set))] for _ in range(len(self.tags_set))])\n",
        "\n",
        "        self.tag_to_idx = {}\n",
        "        self.idx_to_tag = {}\n",
        "        for idx, el in enumerate(self.tags_set):\n",
        "          self.tag_to_idx[el] = idx\n",
        "          self.idx_to_tag[idx] = el\n",
        "\n",
        "\n",
        "        # B = |X|x|T|\n",
        "        words_arr = [inner[0].lower()\n",
        "              for outer in brown_tagged_sents\n",
        "                for inner in outer]\n",
        "        self.words_set = set(words_arr)\n",
        "        self.B = np.array([[0 for _ in range(len(self.tags_set))] for _ in range(len(self.words_set))])\n",
        "\n",
        "        self.word_to_idx = {}\n",
        "        self.idx_to_word = {}\n",
        "        for idx, el in enumerate(self.words_set):\n",
        "          self.word_to_idx[el] = idx\n",
        "          self.idx_to_word[idx] = el\n",
        "\n",
        "        for sent in train_tokens_tags_list:\n",
        "          for i in range(len(sent)):\n",
        "            cur_tag = sent[i][1]\n",
        "            cur_word = sent[i][0].lower()\n",
        "            if i >= 1:\n",
        "              prev_tag = sent[i-1][1]\n",
        "              self.A[self.tag_to_idx[cur_tag]][self.tag_to_idx[prev_tag]] += 1\n",
        "            self.B[self.word_to_idx[cur_word]][self.tag_to_idx[cur_tag]] += 1\n",
        "\n",
        "        self.B = self.B + self.k_smoothing\n",
        "        self.B = self.B / self.B.sum(axis=1)[:,None]\n",
        "        self.A = self.A / self.A.sum(axis=1)[:,None]\n",
        "        self.B[np.isnan(self.B)] = 0\n",
        "        \n",
        "    \n",
        "    def predict(self, test_tokens_list):\n",
        "        \"\"\"\n",
        "        Return predictions for test_tokens_list using viterbi algorithm.\n",
        "        \n",
        "        test_tokens_list : list of list of tokens\n",
        "        \n",
        "        return: list of list of tags\n",
        "        \"\"\"\n",
        "        all_tags = []\n",
        "        for sent in test_tokens_list:\n",
        "          tags = []\n",
        "\n",
        "          prev_probs = [0] * len(self.tags_set)\n",
        "          for el in self.idx_to_tag:\n",
        "            prev_probs[el] += self.B[self.word_to_idx[sent[0].lower()]][el]\n",
        "            first_tag = self.idx_to_tag[np.argmax(prev_probs)]\n",
        "\n",
        "          tags.append(np.argmax(prev_probs))\n",
        "\n",
        "          for idx in range(1, len(sent)):\n",
        "            cur_probs = [0] * len(self.tags_set)\n",
        "            for k in self.idx_to_tag:\n",
        "              tmp_arr = []\n",
        "              for m in self.idx_to_tag:\n",
        "                tmp = np.log((prev_probs[m])) + \\\n",
        "                      np.log((self.A[k][m])) + \\\n",
        "                      np.log((self.B[self.word_to_idx[sent[idx].lower()]][k]))\n",
        "                tmp_arr.append(tmp)\n",
        "              cur_probs[k] = max(tmp_arr)\n",
        "            tags.append(np.argmax(cur_probs))\n",
        "          prev_probs = np.copy(cur_probs)\n",
        "\n",
        "          all_tags.append([self.idx_to_tag[el] for el in tags])\n",
        "          \n",
        "        return all_tags"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwNXJ-d4w0uM",
        "colab_type": "text"
      },
      "source": [
        "Обучите скрытую марковскую модель:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUzO51nCw0uN",
        "colab_type": "code",
        "outputId": "58f1f38f-0fa5-4e15-8065-71468b99bb79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "hmm = HiddenMarkovModel(0.05)\n",
        "hmm.fit(train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 9.97 s, sys: 276 ms, total: 10.3 s\n",
            "Wall time: 10.3 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ECq4Mx-w0uR",
        "colab_type": "text"
      },
      "source": [
        "Проверьте работу реализованного алгоритма на следующих модельных примерах, проинтерпретируйте результат.\n",
        "\n",
        "- 'he can stay'\n",
        "- 'a milk can'\n",
        "- 'i saw a dog'\n",
        "- 'an old saw'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXyVoVGWw0uR",
        "colab_type": "code",
        "outputId": "8a8ee221-e468-496e-8743-1ad2b73269b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "hmm.predict([\n",
        "    ['he', 'can', 'stay'],\n",
        "    ['a', 'milk', 'can'],\n",
        "    ['i', 'saw', 'a', 'dog'],\n",
        "    ['an', 'old', 'saw']\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['PRON', 'VERB', 'VERB'],\n",
              " ['DET', 'NOUN', 'VERB'],\n",
              " ['PRON', 'VERB', 'DET', 'NOUN'],\n",
              " ['DET', 'ADJ', 'VERB']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghOxrTDOw0uT",
        "colab_type": "text"
      },
      "source": [
        "Примените модель к отложенной выборке Брауновского корпуса и подсчитайте точность определения тегов (accuracy). Сделайте выводы. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvku1hwRw0uU",
        "colab_type": "code",
        "outputId": "d6e2cd44-acb4-47fd-dbec-19c903c117df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "test_X = []\n",
        "test_y = []\n",
        "\n",
        "for sent in test:\n",
        "  test_X.append([el[0] for el in sent])\n",
        "  test_y.append([el[1] for el in sent])\n",
        "  \n",
        "pred_y = hmm.predict(test_X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 26s, sys: 148 ms, total: 1min 26s\n",
            "Wall time: 1min 26s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ensp5B09ShJQ",
        "colab_type": "code",
        "outputId": "64948353-7f1f-48fc-a3ed-c55b2dcd4504",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred_y = np.array([item for sublist in pred_y for item in sublist])\n",
        "test_y = np.array([item for sublist in test_y for item in sublist])\n",
        "print(sum(pred_y == test_y) / len(pred_y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9191163830153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWrXkyZKXBFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# without smoothing \n",
        "0.9136579603169812\n",
        "# with smoothing 1.0\n",
        "0.8802266122843173\n",
        "# with smoothing 0.1\n",
        "0.9133820245065492\n",
        "# with smoothing \n",
        "0.9192321653903994"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIjkoa2_w0uX",
        "colab_type": "text"
      },
      "source": [
        "## Бонусная часть. Сравнение с готовыми POS-теггерами из NLTK (2 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIgGEaNqw0uY",
        "colab_type": "text"
      },
      "source": [
        "В прошлом пункте Вы реализовали свой POS-тегер на основе скрытой марковской модели. Теперь сравните его работу с готовыми средставми, доступными в библиотеке NLTK: http://www.nltk.org/api/nltk.tag.html\n",
        "\n",
        "Сравните с вашей моделью любые из 4-х теггеров, представленных ниже."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMdkcUVUw0ua",
        "colab_type": "text"
      },
      "source": [
        "При проведении экспериментов обращайте внимание на следующие моменты (и отразите их в отчете):\n",
        "- Какой подход лежит в основе теггера\n",
        "- На каких данных он обучен (если Вы скачали готовую модель)\n",
        "- Сколько времени занимает обучение на brown корпусе (если обучаете сами)\n",
        "- Какая точность получается на контролькой выборке\n",
        "\n",
        "Сформируйте рекоммендиции о том, какую технологию Вы бы использовали, если встретитесь с задачей определения частей речи в будущем."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWmykuJ-w0ub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk.tag.mapping import map_tag"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yodXtWxZw0ud",
        "colab_type": "text"
      },
      "source": [
        "### 1. DefaultTagger\n",
        "Простая заглушка, ставящая всем словам один и тот же pos-тег. Очевидно, для максимизации качества, мы хотим выбрать самую частотную метку из всех меток обучающей выборки, т.е. метку 'NOUN'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quYqyCkmw0ud",
        "colab_type": "code",
        "outputId": "bbf1940e-2918-44fe-96c4-982bf1a93754",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from nltk.tag import DefaultTagger\n",
        "default_tagger = DefaultTagger(u'NOUN')\n",
        "\n",
        "print('train:', default_tagger.evaluate(brown_tagged_sents))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train: 0.23730614747604187\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3mwVyPkw0ue",
        "colab_type": "text"
      },
      "source": [
        "### 2. RegexpTagger\n",
        "\n",
        "Теггер, который присваивает слову часть речи, основываясь на регулярных выражениях. Например, ставить слову метку 'NOUN', если слово кончается на 'ness'. Ниже приведен простой пример возможных правил. В качестве backoff теггера использован DefaultTagger.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7_TtPmWw0uf",
        "colab_type": "code",
        "outputId": "5ae3a4ce-e29c-4d82-be24-550bb1b69769",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from nltk.tag import RegexpTagger\n",
        "\n",
        "regexp_tagger = RegexpTagger(regexps=[(r'^-?[0-9]+(.[0-9]+)?$', 'CD'),   # cardinal numbers\n",
        "                                      (r'(The|the|A|a|An|an)$', 'AT'),   # articles\n",
        "                                      (r'.*able$', 'JJ'),                # adjectives\n",
        "                                      (r'.*ness$', 'NN'),                # nouns formed from adjectives\n",
        "                                      (r'.*ly$', 'RB'),                  # adverbs\n",
        "                                      (r'.*s$', 'NNS'),                  # plural nouns\n",
        "                                      (r'.*ing$', 'VBG'),                # gerunds\n",
        "                                      (r'.*ed$', 'VBD'),                 # past tense verbs\n",
        "                                      (r'.*', 'NN')                      # nouns (default)\n",
        "                                     ],\n",
        "                             backoff=default_tagger)\n",
        "\n",
        "# your code here\n",
        "# use map_tag() to tranform 'en-ptb' to 'universal' tags.\n",
        "X = [[el[0] for el in sent] \n",
        "     for sent in brown_tagged_sents]\n",
        "\n",
        "pred_all = regexp_tagger.tag_sents(X)\n",
        "\n",
        "pred = [map_tag('en-ptb', 'universal', el[1]) for sent in pred_all\n",
        "        for el in sent]\n",
        "\n",
        "true = [el[1] for sent in brown_tagged_sents\n",
        "        for el in sent]\n",
        "\n",
        "sum([pred[i] == true[i] for i in range(len(true))])/len(true)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.30036893123617797"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUsMl-wmw0ug",
        "colab_type": "text"
      },
      "source": [
        "### 3. N-грамные теггеры\n",
        "\n",
        "В теггерах, основанных на n-граммах,  принятие решения происходит в зависимости от $n-1$ предыдущих слов и их тегов. Эти теггеры необходимо обучать по размеченной обучающей коллекции. \n",
        "\n",
        "Заметим, что TrigramTagger и BigramTagger работают очень плохо без указания backoff. Поэтому предлагается построить композицию, где \n",
        "в качестве backoff для UnigramTagger использовать DefaultTagger, для BigramTagger использовать UnigramTagger, для TrigramTagger  использовать BigramTagger. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlh7Q0gxw0ug",
        "colab_type": "code",
        "outputId": "7583ebee-1dc1-4c35-af19-3b69df7eb2d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "from nltk.tag import UnigramTagger\n",
        "from nltk.tag import BigramTagger\n",
        "from nltk.tag import TrigramTagger\n",
        "\n",
        "u_tagger = UnigramTagger(train, backoff=default_tagger)\n",
        "print('UnigramTagger')\n",
        "print('train:', u_tagger.evaluate(train))\n",
        "print('test:', u_tagger.evaluate(test))\n",
        "\n",
        "b_tagger = BigramTagger(train, backoff=u_tagger)\n",
        "print('BigramTagger')\n",
        "print('train:', b_tagger.evaluate(train))\n",
        "print('test:', b_tagger.evaluate(test))\n",
        "\n",
        "t_tagger = TrigramTagger(train, backoff=b_tagger)\n",
        "print('TrigramTagger')\n",
        "print('train:', t_tagger.evaluate(train))\n",
        "print('test:', t_tagger.evaluate(test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UnigramTagger\n",
            "train: 0.9571039726200458\n",
            "test: 0.9461320268179474\n",
            "BigramTagger\n",
            "train: 0.9691429982428134\n",
            "test: 0.9544180849235001\n",
            "TrigramTagger\n",
            "train: 0.9728736701465853\n",
            "test: 0.954039883101255\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lqc88AHTw0ui",
        "colab_type": "text"
      },
      "source": [
        "### 4. Stanford tagger\n",
        "\n",
        "Скачайте предобученную модель от Стэнфорда: https://nlp.stanford.edu/software/tagger.shtml и примените к тестовым данным. \n",
        "Не забудьте преобразовать систему тэгов из 'en-ptb' в 'universal' с помощью функции map_tag."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a01miLSDw0ui",
        "colab_type": "code",
        "outputId": "8b576898-8214-472e-99c1-773c411fdf48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from nltk.tag.stanford import StanfordPOSTagger\n",
        "\n",
        "# Add the jar and model via their path:\n",
        "jar = 'stanford-postagger-3.9.2.jar'\n",
        "model = 'english-bidirectional-distsim.tagger'\n",
        "stanford_tagger = StanfordPOSTagger(model, jar, encoding='utf8')\n",
        "\n",
        "X = [[el[0] for el in sent] \n",
        "     for sent in brown_tagged_sents]\n",
        "\n",
        "pred_all = stanford_tagger.tag_sents(X)\n",
        "\n",
        "pred = [map_tag('en-ptb', 'universal', el[1]) for sent in pred_all\n",
        "        for el in sent]\n",
        "\n",
        "true = [el[1] for sent in brown_tagged_sents\n",
        "        for el in sent]\n",
        "\n",
        "sum([pred[i] == true[i] for i in range(len(true))])/len(true)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/tag/stanford.py:149: DeprecationWarning: \n",
            "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
            "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
            "  super(StanfordPOSTagger, self).__init__(*args, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9249745089528691"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIupDtHaw0uk",
        "colab_type": "text"
      },
      "source": [
        "### 5. Теггеры из NLTK на основе графических моделей\n",
        "\n",
        "Обучите теггер, основанный на HMM или CRF, на основе класса из nltk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFZ_4WP3w0ul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tag import HiddenMarkovModelTagger, CRFTagger"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "896AusBuw0um",
        "colab_type": "text"
      },
      "source": [
        "### Сравнение моделей\n",
        "\n",
        "Сравните различные модели по качеству, сделайте выводы."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsW6hSiBw0um",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# my HMM without smoothing \n",
        "0.9136579603169812\n",
        "# my HMM with smoothing 1.0\n",
        "0.8802266122843173\n",
        "# my HMM with smoothing 0.1\n",
        "0.9133820245065492\n",
        "# my HMM with smoothing 0.05\n",
        "0.9191163830153\n",
        "\n",
        "Очевидно, что это очень \"не умный\" тегер\n",
        "# DefaultTagger\n",
        "0.23730614747604187\n",
        "\n",
        "Этот тегер чуть умнее, но очевидно, что регулярными выражениями очень сложно отловить все зависимости.\n",
        "# RegExpTagger\n",
        "0.30036893123617797\n",
        "\n",
        "Этот тегер учитывает контекст размером 1, то есть для предсказывания тэга слова используется предыдещее слово.\n",
        "# UnigramTagger\n",
        "train: 0.9571039726200458\n",
        "test: 0.9461320268179474\n",
        "  \n",
        "Этот тегер учитывает контекст размером 2, то есть для предсказывания тэга слова используются 2 предыдещих слово.\n",
        "# BigramTagger\n",
        "train: 0.9691429982428134\n",
        "test: 0.9544180849235001\n",
        "  \n",
        "Этот тегер учитывает контекст размером 2, то есть для предсказывания тэга слова используются 3 предыдещих слово.\n",
        "# TrigramTagger\n",
        "train: 0.9728736701465853\n",
        "test: 0.954039883101255\n",
        "  \n",
        "Так как мы добавили параметр backoff, то при отказе классификации жтим тэгером используется тот, который в указан.\n",
        "  \n",
        "Основные идеи: \n",
        "  1. явное использование как предшествующего, так и последующего текстовых тегов через сетевое представление зависимостей\n",
        "  2. широкое использование лексических признаков\n",
        "  3. эффективное использование логлинейный моделей\n",
        "  4. детальная обработка неизвестных слов.\n",
        "\n",
        "# StanfordTagger\n",
        "0.9249745089528691"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}