{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9TplUT8Lxcbo"
   },
   "source": [
    "<font color='blue'>Все мои комментарии будут написаны синим цветом.\n",
    "</font>\n",
    "</br>\n",
    "<font color='blue'>\n",
    "Следующая ячейка импортирует файлы из Google Drive\n",
    "</font>\n",
    "</br>\n",
    "<font color='blue'>\n",
    "файл tests.py надо переименовать на testss.py\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "NsPMnWwJwpzX",
    "outputId": "86dee0a0-370e-4581-df86-bfc663c3fdb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from google.colab import drive\n",
    "import sys\n",
    "\n",
    "\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "train_path = \"./gdrive/My Drive/mmta/HW1/data/train.tsv\"\n",
    "validation_path = \"./gdrive/My Drive/mmta/HW1/data/validation.tsv\"\n",
    "\n",
    "def read_corpus(filename):\n",
    "    data = []\n",
    "    for line in open(filename, encoding='utf-8'):\n",
    "        data.append(line.strip().split('\\t'))\n",
    "    return data\n",
    "  \n",
    "validation = read_corpus(validation_path)\n",
    "\n",
    "sys.path.append('./gdrive/My Drive/mmta/HW1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZeCgq7M5wbZU"
   },
   "source": [
    "# Практическое задание 1\n",
    "\n",
    "# Ранжирование вопросов StackOverflow с помощью векторных представлений слов\n",
    "\n",
    "## курс \"Математические методы анализа текстов\"\n",
    "\n",
    "\n",
    "### ФИО: Хуршудов Артем Эрнестович"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cBcNcaC6wbZW"
   },
   "source": [
    "## Введение\n",
    "\n",
    "В этом задании вы научитесь вычислять близость текстов и применить этот метод для поиска похожих вопросов на [StackOverflow](https://stackoverflow.com).\n",
    "\n",
    "### Используемые библиотеки\n",
    "\n",
    "В данном задании потребуются следующие библиотеки:\n",
    "- [Gensim](https://radimrehurek.com/gensim/) — инструмент для решения различных задач NLP (тематическое моделирование, представление текстов, ...).\n",
    "- [Numpy](http://www.numpy.org) — библиотека для научных вычислений.\n",
    "- [scikit-learn](http://scikit-learn.org/stable/index.html) — библилиотека с многими реализованными алгоритмами машинного обучения для анализа данных.\n",
    "- [Nltk](http://www.nltk.org) — инструмент для работы с естественными языками.\n",
    "\n",
    "Для выполнения бонусной части потребуется:\n",
    "- [StarSpace](https://github.com/facebookresearch/StarSpace) — универсальная модель для обучения различных векторных представлений, разработанная командой Facebook.\n",
    "\n",
    "\n",
    "### Данные\n",
    "\n",
    "Данные лежат в архиве `StackOverflowData.zip`, который состоит из:\n",
    "- `train.tsv` - обучающая выборка. В каждой строке через табуляцию записаны дублирующие друг друга предложения;\n",
    "- `test.tsv` - тестовая выборка. В каждой строке через табуляцию записаны: *<вопрос>, <похожий вопрос>, <отрицательный пример 1>, <отрицательный пример 2>, ...*\n",
    "\n",
    "Скачать архив можно здесь: [ссылка на google диск](https://drive.google.com/open?id=1QqT4D0EoqJTy7v9VrNCYD-m964XZFR7_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6is1blbMwbZX"
   },
   "source": [
    "### Вектора слов/\n",
    "\n",
    "Для решения вам потребуются две модели векторных представлений слов:\n",
    "\n",
    " - [Предобученные векторные представления слов](https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit), которые были обучены с помощью стандартной модели word2vec на данных Google News (100 миллиардов слов). Модель содержит 300-мерные вектора для 3 миллионов слов и фраз. Вы можете скачать их, запустив блок кода ниже.\n",
    " - Векторные представления слов, полученные с помощью StarSpace на выборке StackOverflow. Вам потребуется обучить эту модель самим во второй части задания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "xl5MDWnwwbZb",
    "outputId": "7887c89a-46c0-41b7-b478-5a2769c78738"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading GoogleNews-vectors-negative300.bin.gz (1.5G) for you, it will take a while...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b0ab8c5e0f4390a57295a321de1625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1647046227), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Download Google vectors to directory *target_dir*\n",
    "\n",
    "from download_utils import download_google_vectors\n",
    "download_google_vectors(target_dir='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HBxhp12BwbZi"
   },
   "source": [
    "## Часть 1. Предобученные векторные представления слов (2 балла)\n",
    "\n",
    "Скачайте предобученные вектора и загрузите их с помощью функции [KeyedVectors.load_word2vec_format](https://radimrehurek.com/gensim/models/keyedvectors.html) библиотеки Gensim с параметром *binary=True*. Если суммарный размер векторов больше, чем доступная память, то вы можете загрузите только часть векторов, указав параметр *limit* (рекомендуемое значение: 500000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tVATgTwMwbZj"
   },
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "LR4XCz8owbZm",
    "outputId": "cfa1583e-de10-4e2f-bbf3-26f3675f4831"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "google_emb_path = '/content/GoogleNews-vectors-negative300.bin.gz'\n",
    "wv_embeddings = gensim.models.KeyedVectors.load_word2vec_format(google_emb_path,\n",
    "                                                                binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "kCUa57bQ19T2",
    "outputId": "a136c19f-0878-4efa-fdec-37ab93c50df4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "0.4649958610534668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "print('c++' in wv_embeddings)\n",
    "print('hi' in wv_embeddings)\n",
    "print(wv_embeddings.distance('france', 'France'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IOgJX0tXwbZp"
   },
   "source": [
    "### Как пользоваться этими векторами?\n",
    "\n",
    "Как только вы загрузите векторные представления слов в память, убедитесь, что имеете к ним доступ. Сначала вы можете проверить, содержится ли какое-то слово в загруженных эмбедингах:\n",
    "\n",
    "    'word' in wv_embeddings\n",
    "\n",
    "Затем, чтобы получить соответствующий вектор, вы можете использовать оператор доступа по ключу:\n",
    "\n",
    "    wv_embeddings['word']\n",
    "\n",
    "### Проверим, корректны ли векторные представления\n",
    "\n",
    "Чтобы предотвратить возможные ошибки во время первого этапа, можно проверить, что загруженные вектора корректны. Для этого вы можете запустить функцию *check_embeddings*. Она запускает 3 теста:\n",
    "1. Находит наиболее похожие слова для заданных \"положительных\" и \"отрицательных\" слов.\n",
    "2. Находит, какое слово из заданного списка не встречается с остальными.\n",
    "3. Находит наиболее похожее слово для заданного."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "eFa9sHMewbZq",
    "outputId": "39cb664c-ca0e-4d71-deed-746a339ab3e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These embeddings look good.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    }
   ],
   "source": [
    "from testss import check_embeddings\n",
    "print(check_embeddings(wv_embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YtaxFDfLwbZt"
   },
   "source": [
    "### Векторные представления текста\n",
    "\n",
    "Чтобы перейти от отдельных слов к векторным представлениям вопросов, предлагается подсчитать **среднее** векторов всех слов в вопросе. Если для какого-то слова нет предобученного вектоора, то его нужно пропустить. Если вопрос не содержит ни одного известного слова, то нужно вернуть нулевой вектор. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rmeT_WITwbZt"
   },
   "source": [
    "<font color='red'>**Реализуйте функцию *question_to_vec_by_mean*, работающую по такой логике. **</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "-lqf6Jk0wbZu",
    "outputId": "6aee9d87-1963-407e-8ef8-00d4952c3e91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ROZBIjCywbZv"
   },
   "outputs": [],
   "source": [
    "def question_to_vec_by_mean(question, embeddings, dim=300):\n",
    "    \"\"\"\n",
    "        question: a string\n",
    "        embeddings: dict where the key is a word and a value is its' embedding\n",
    "        dim: size of the representation\n",
    "\n",
    "        result: vector representation for the question\n",
    "    \"\"\"\n",
    "    tokens = word_tokenize(question)\n",
    "\n",
    "    emb = [embeddings[t] for t in tokens if t in embeddings]\n",
    "    if emb == list():\n",
    "      emb = [np.zeros(dim)]\n",
    "    return np.mean(emb, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nd5vbgYnwbZw"
   },
   "source": [
    "Для базовой проверки решения запустите клетку ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "aBQKPEwg8-NU",
    "outputId": "b136ad3b-e769-41f3-8637-be5cde8f8f60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n",
      "0.0\n",
      "(300,)\n",
      "-0.91374505\n"
     ]
    }
   ],
   "source": [
    "print(question_to_vec_by_mean('asdandwadawd', wv_embeddings).shape)\n",
    "print(question_to_vec_by_mean('asdandwadawd', wv_embeddings).sum())\n",
    "print(question_to_vec_by_mean('How are you?', wv_embeddings).shape)\n",
    "print(question_to_vec_by_mean('How are you?', wv_embeddings).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LzXQwa3gwbZx",
    "outputId": "5bf76b34-a5b3-4c7b-e026-355643f85f57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic tests are passed.\n"
     ]
    }
   ],
   "source": [
    "from testss import question_to_vec_tests\n",
    "\n",
    "print(question_to_vec_tests(question_to_vec_by_mean, wv_embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "97TH4YTrwbZy"
   },
   "source": [
    "Теперь у нас есть метод для создания векторного представления любого предложения. Оценим, как будет работать это решение.\n",
    "\n",
    "### Оценка близости текстов\n",
    "\n",
    "Представим, что мы используем идеальные векторные представления слов. Тогда косинусное расстояние между дублирующими предложениями должно быть меньше, чем между случайно взятыми предложениями. \n",
    "\n",
    "Сгенерируем для каждого из *N* вопросов *R* случайных отрицательных примеров и примешаем к ним также настоящие дубликаты. Для каждого вопроса будем ранжировать с помощью нашей модели *R + 1* примеров и смотреть на позицию дубликата.\n",
    "\n",
    "#### Hits@K\n",
    "Первой простой метрикой будет количество корректных попаданий для какого-то *K*:\n",
    "$$ \\text{Hits@K} = \\frac{1}{N}\\sum_{i=1}^N \\, [dup_i \\in topK(q_i)],$$\n",
    "где $q_i$ - $i$-ый вопрос, $dup_i$ - его дубликат, $topK(q_i)$ - первые *K* элементов в ранжированном списке, который выдает наша модель.\n",
    "\n",
    "#### DCG@K\n",
    "Второй метрикой будет упрощенная [DCG метрика](https://en.wikipedia.org/wiki/Discounted_cumulative_gain):\n",
    "$$ \\text{DCG@K} = \\frac{1}{N} \\sum_{i=1}^N\\frac{1}{\\log_2(1+rank_{dup_i})}\\cdot[rank_{dup_i} \\le K],$$\n",
    "где $rank_{dup_i}$ - позиция дубликата в ранжированном списке ближайших предложений для вопроса $q_i$. С такой метрикой модель штрафуется за низкую позицию корректного ответа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bU1nYURXwbZy"
   },
   "source": [
    "#### Пример оценок\n",
    "\n",
    "Вычислим описанные выше метрики для игрушечного примера. Пусть $N = 1$, $R = 3$, вопрос $q_1$ это \"Что такое python\", а его дубликат $dup_1$ это \"Что такое язык python\". Пусть модель выдала следующий ранжированный список кандидатов:\n",
    "\n",
    "1. *\"Как узнать с++\"*\n",
    "2. *\"Что такое язык python\"*\n",
    "3. *\"Хочу учить Java\"*\n",
    "4. *\"Не понимаю Tensorflow\"*\n",
    "\n",
    "Вычислим метрику *Hits@K* для *K = 1, 4*:\n",
    "\n",
    "- [K = 1] $\\text{Hits@1} =  [dup_1 \\in top1(q_1)] = 0$\n",
    "- [K = 4] $\\text{Hits@4} =  [dup_1 \\in top4(q_1)] = 1$\n",
    "\n",
    "Вычислим метрику *DCG@K* для *K = 1, 4*:\n",
    "- [K = 1] $\\text{DCG@1} = \\frac{1}{\\log_2(1+2)}\\cdot[2 \\le 1] = 0$\n",
    "- [K = 4] $\\text{DCG@4} = \\frac{1}{\\log_2(1+2)}\\cdot[2 \\le 4] = \\frac{1}{\\log_2{3}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "th4-t9ASwbZz"
   },
   "source": [
    "<font color='red'>**Реализуйте функции *hits_count* и *dcg_score*. **</font> \n",
    "\n",
    "Каждая функция имеет два аргумента: *dup_ranks* и *k*. *dup_ranks* является списком, который содржит *рейтинги дубликатов* (их позиции в ранжированном списке). Например, *dup_ranks = [2]* для примера, описанного выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1McXQojQwbZz"
   },
   "outputs": [],
   "source": [
    "def hits_count(dup_ranks, k):\n",
    "    \"\"\"\n",
    "        dup_ranks: list of ranks of the duplicates; one rank per question; \n",
    "                   length is a number of questions that we check (N); \n",
    "                   rank is a number from 1 to len(candidates for the question).\n",
    "        k: number of top-ranked elements (k in Hits@k metric)\n",
    "\n",
    "        result: return Hits@k value for the current ranking.\n",
    "    \"\"\"\n",
    "    return np.mean(np.array(dup_ranks) <= k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lq637UkfwbZ1"
   },
   "outputs": [],
   "source": [
    "def dcg_score(dup_ranks, k):\n",
    "    \"\"\"\n",
    "        dup_ranks: list of ranks of the duplicates; one rank per question; \n",
    "                   length is a number of questions that we check (N); \n",
    "                   rank is a number from 1 to len(candidates for the question).\n",
    "        k: number of top-ranked elements (k in DCG@k metric)\n",
    "\n",
    "        result: return DCG@k value for the current ranking.\n",
    "    \"\"\"\n",
    "    return np.mean(np.array([ 1/np.log2(1+rg) * (rg <= k) for rg in dup_ranks ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UzRCJnCywbZ2"
   },
   "source": [
    "Протестируйте функции. Успешное прохождение базовых тестов еще не гарантирует корректности реализации!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XrcwRx30wbZ2",
    "outputId": "a1a1b21e-dc1b-48ab-b637-3c4a402b5fb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic test are passed.\n"
     ]
    }
   ],
   "source": [
    "from testss import test_hits\n",
    "print(test_hits(hits_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "csqhhxlfwbZ3",
    "outputId": "ac1f440c-5d24-4b01-fba2-4cbe7c90345e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic test are passed.\n"
     ]
    }
   ],
   "source": [
    "from testss import test_dcg\n",
    "print(test_dcg(dcg_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "1_J_vPX3BAlJ",
    "outputId": "f3c2aedb-9d3d-4579-da1f-a78ab7f492c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "0.23114213453909027\n"
     ]
    }
   ],
   "source": [
    "print(hits_count([6, 6, 6, 6, 5, 1], 5))\n",
    "print(dcg_score([6, 6, 6, 6, 5, 1], 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9uqctDKHwbZ4"
   },
   "source": [
    "### Ранжирование вопросов StackOverflow\n",
    "\n",
    "Выборка уже разбита на обучающую и тестовую. Все файлы используют табуляцию в качестве разделителя, но они имеют разный формат:\n",
    "\n",
    "- *обучающая* выборка (test.tsv) содержит похожие друг на друга предложения в каждой строке;\n",
    "- *тестовая* выборка (validation.tsv) содержит в каждой строке: *вопрос, похожий вопрос, отрицательный пример 1, отрицательный пример 2, ...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rlxJVHZ5wbZ5"
   },
   "source": [
    "Считайте тестовую выборку для оценки качества текущего решения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PAT-Um06wbZ5"
   },
   "outputs": [],
   "source": [
    "def read_corpus(filename):\n",
    "    data = []\n",
    "    for line in open(filename, encoding='utf-8'):\n",
    "        data.append(line.strip().split('\\t'))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v8uEdSewwbZ6"
   },
   "outputs": [],
   "source": [
    "validation = read_corpus(validation_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WIaGycGWwbZ7"
   },
   "source": [
    "<font color='red'>**Реализуйте функцию ранжирования кандидатов на основе косинусного расстояния.**</font>\n",
    "    \n",
    "Функция должна по списку кандидатов вернуть отсортированный список пар (позиция в исходном списке кандидатов, кандидат). При этом позиция кандидата в полученном списке является его рейтингом (первый - лучший). Например, если исходный список кандидатов был [a, b, c], и самый похожий на исходный вопрос среди них - c, затем a, и в конце b, то функция должна вернуть список *[(2, c), (0, a), (1, b)]*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mii_N6JIwbZ7"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bGUy_DJfwbZ8"
   },
   "outputs": [],
   "source": [
    "def rank_candidates(question, candidates, embeddings, dim=300):\n",
    "    \"\"\"\n",
    "        question: a string\n",
    "        candidates: a list of strings (candidates) which we want to rank\n",
    "        embeddings: some embeddings\n",
    "        dim: dimension of the current embeddings\n",
    "        \n",
    "        result: a list of pairs (initial position in the list, question)\n",
    "    \"\"\"\n",
    "    question_emb = question_to_vec_by_mean(question, embeddings, dim)\n",
    "    \n",
    "    return sorted(list(enumerate(candidates)),\n",
    "                  reverse=True,\n",
    "                  key=lambda x: cosine_similarity(\n",
    "                      [\n",
    "                          question_to_vec_by_mean(x[1],\n",
    "                                                  embeddings,\n",
    "                                                  dim)\n",
    "                      ],\n",
    "                      [question_emb]\n",
    "                  )\n",
    "                 )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iU6fn6sawbZ9"
   },
   "source": [
    "Протестируйте работу функции на примерах ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JsNcMJFbwbZ9",
    "outputId": "826d4453-7e94-4cf2-f730-9b38325ea0e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic tests are passed.\n"
     ]
    }
   ],
   "source": [
    "from testss import test_rank_candidates\n",
    "print(test_rank_candidates(rank_candidates, wv_embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ktXiOX11wbZ-"
   },
   "source": [
    "Теперь мы можем оценить качество нашего метода. Запустите следующие два блока кода для получения результата. Обратите внимание, что вычисление расстояния между векторами занимает некоторое время (примерно 10 минут)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mcjLGmnQNq8r"
   },
   "outputs": [],
   "source": [
    "dont rerun _next two cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "k3IdibdxwbaB",
    "outputId": "3befb257-69a5-48e3-c700-ec5041a5f860"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3760/3760 [21:36<00:00,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21min 35s, sys: 2.54 s, total: 21min 38s\n",
      "Wall time: 21min 36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "wv_ranking = []\n",
    "for line in tqdm(validation):\n",
    "    q, *ex = line\n",
    "    ranks = rank_candidates(q, ex, wv_embeddings)\n",
    "    wv_ranking.append([r[0] for r in ranks].index(0) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "E-41xY73wbaE",
    "outputId": "616731d9-25c8-401c-cc8b-eb3d74c9491e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@   1: 0.251 | Hits@   1: 0.251\n",
      "DCG@   5: 0.304 | Hits@   5: 0.351\n",
      "DCG@  10: 0.321 | Hits@  10: 0.404\n",
      "DCG@ 100: 0.362 | Hits@ 100: 0.611\n",
      "DCG@ 500: 0.392 | Hits@ 500: 0.842\n",
      "DCG@1000: 0.408 | Hits@1000: 1.000\n"
     ]
    }
   ],
   "source": [
    "for k in [1, 5, 10, 100, 500, 1000]:\n",
    "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), k, hits_count(wv_ranking, k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "noVqNRc8GzOj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vVIlEWwcwbaH"
   },
   "source": [
    "Если вы проделали все шаги правильно, то вы должны разочароваться полученными результатами. Давайте попробуем понять, почему качество модели такое низкое. Когда вы работаете с какими-либо данными, очень полезно первым делом посмотреть на них глазами. Выведите несколько вопросов из наших данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "-piRo5BmwbaH",
    "outputId": "eda8a5d6-a900-448d-f279-1bb9ae06fe28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to print a binary heap tree without recursion? How do you best convert a recursive function to an iterative one? How can i use ng-model with directive in angular js flash: drawing and erasing\n",
      "\n",
      "How to start PhoneStateListener programmatically? PhoneStateListener and service Java cast object[] to model WCF and What does this mean?\n",
      "\n",
      "jQuery: Show a div2 when mousenter over div1 is over when hover on div1 depenting on if it is on div2 or not it should act differently How to run selenium in google app engine/cloud? Python Comparing two lists of strings for similarities\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in validation[:3]:\n",
    "    q, *examples = line\n",
    "    print(q, *examples[:3])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OzFSYHtlwbaI"
   },
   "source": [
    "## Часть 2. Предобработка данных (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pS03PCUUwbaI"
   },
   "source": [
    "Как вы могли заметить, мы имеем дело с сырыми данными. Это означает, что там присутствует много опечаток, спецсимволов и заглавных букв. В нашем случае это все может привести к ситуации, когда для данных токенов нет предобученных векторов. Поэтому необходима предобработка."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q4K1Hra6wbaJ"
   },
   "source": [
    "<font color='red'>**Реализуйте функцию предобработки текстов.**</font>\n",
    "\n",
    "Вам требуется:\n",
    "- Перевести символы в нижний регистр;\n",
    "- Заменить символы пунктуации на пробелы;\n",
    "- Удалить \"плохие\" символы;\n",
    "- Удалить стопслова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "57kwtaq0wbaJ",
    "outputId": "ad065838-33a1-4fee-e914-3406a8a38c68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bhbA_7riHCbK"
   },
   "source": [
    "<font color='blue'>\n",
    "  Здесь используется простой препроцессинг, удаляется все, кроме букв, т.к. в wv_embeddings нет таких слов как 'c++' например. Более того шаг удаления пунктуации можно убрать, так как регулярка все равно удалит знаки припинания.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hk_VGF57wbaK",
    "outputId": "6e63b02f-d022-4e27-b9a0-834c61bfc22d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello world'"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def text_prepare(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified string\n",
    "    \"\"\"\n",
    "    # to lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    # punct -> ' '\n",
    "    punct = string.punctuation\n",
    "    text = text.translate(str.maketrans(punct, ' '*len(punct)))\n",
    "    \n",
    "    # delete all but letters\n",
    "    regex = re.compile('[^a-z ]')\n",
    "    text = re.sub(regex, '', text)\n",
    "    \n",
    "    # removing stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words.add('')\n",
    "    text = [w for w in text.split() if w not in stop_words]\n",
    "    \n",
    "    return ' '.join(text)\n",
    "    \n",
    "text_prepare('Hello World?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pe6DQ9WxwbaL"
   },
   "source": [
    "<font color='red'>**Теперь преобразуйте все вопросы из тестовой выборки. Оцените, как изменилось качество. Сделайте выводы.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lTXToDt0P5y7"
   },
   "outputs": [],
   "source": [
    "dont rerun _next two cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "OicsQMnSwbaM",
    "outputId": "eb1b5be9-0e24-4a3b-82cd-c134e9097e7b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3760/3760 [26:12<00:00,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25min 44s, sys: 28.9 s, total: 26min 13s\n",
      "Wall time: 26min 12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "wv_ranking = []\n",
    "for line in tqdm(validation):\n",
    "    line = map(text_prepare, line)\n",
    "    q, *ex = line\n",
    "    ranks = rank_candidates(q, ex, wv_embeddings)\n",
    "    wv_ranking.append([r[0] for r in ranks].index(0) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "7C-DFcnxIbL6",
    "outputId": "f162ca65-9a6e-409f-f720-1504227dc254"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@   1: 0.355 | Hits@   1: 0.355\n",
      "DCG@   5: 0.425 | Hits@   5: 0.489\n",
      "DCG@  10: 0.442 | Hits@  10: 0.541\n",
      "DCG@ 100: 0.477 | Hits@ 100: 0.717\n",
      "DCG@ 500: 0.496 | Hits@ 500: 0.867\n",
      "DCG@1000: 0.510 | Hits@1000: 1.000\n"
     ]
    }
   ],
   "source": [
    "for k in [1, 5, 10, 100, 500, 1000]:\n",
    "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), k, hits_count(wv_ranking, k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cUDwe2cxwbaM"
   },
   "source": [
    "## Часть 3. Представления для неизвестных слов. (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3YKOS1XpwbaN"
   },
   "source": [
    "<font color='red'>**Оцените долю слов в выборке, для которых нет эмбеддинга в модели.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "sLj7eXfnwbaN",
    "outputId": "f0b67de1-d663-4ad7-fc2b-9133f33c2f28"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3760/3760 [10:09<00:00,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7662 16714 0.4584180926169678\n",
      "CPU times: user 9min 18s, sys: 52.2 s, total: 10min 10s\n",
      "Wall time: 10min 9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from tqdm import tqdm\n",
    "wv_ranking = []\n",
    "s = set()\n",
    "for line in tqdm(validation):\n",
    "    line = map(text_prepare, line)\n",
    "    for sent in line:\n",
    "      words = sent.split()\n",
    "      for w in words:\n",
    "        s.add(w)\n",
    "        \n",
    "count = 0\n",
    "for el in s:\n",
    "  count += (el not in wv_embeddings)\n",
    "  \n",
    "print(count, len(s), count/len(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cl7198rYwbaO"
   },
   "source": [
    "Для того, что получить представления для неизвестного слова, воспользуемся следующим подходом:\n",
    "    \n",
    "1. Будем восстанавливать эмбеддинг неизвестного слова как сумму эмбеддингов буквенных триграмм. Например, слово where должно представляться суммой триграмм _wh, whe, her, ere, re_\n",
    "\n",
    "2. В качестве обучающих данных будем использовать слова, для которых есть эмбеддинг в модели. Будем обучать эмбеддинги триграмм по выборке эмбеддингов с помощью функционала MSE:\n",
    "\n",
    "$$L = \\sum_{w \\in W_{known}}\\| f_{\\theta}(w) - v_w \\|^2 \\to \\min_{\\theta}$$\n",
    "\n",
    "где:\n",
    "\n",
    "* $W_{known}$ — множество известных модели слов\n",
    "* $f_{\\theta}(w)$ — сумма эмбеддингов триграмм слова $w$\n",
    "* $v_w$ — эмбеддинг слова $w$\n",
    "* $\\theta$ — веса эмбеддингов триграмм"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uywLzs0WwbaO"
   },
   "source": [
    "<font color='red'>**Реализуйте предложенную модель ниже.**</font>\n",
    "\n",
    "Используйте класс nn.EmbeddingBag для построения среднего вектора представлений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cSk3uGbzwbaO"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K_BWYlkiK0Mx"
   },
   "outputs": [],
   "source": [
    "def split_trigrams(word, \n",
    "                   n=3, \n",
    "                   pad_left=True,\n",
    "                   pad_right=True,\n",
    "                   left_pad_symbol='_',\n",
    "                   right_pad_symbol='_'):\n",
    "  tmp = list(ngrams(word, 3,\n",
    "                    pad_left=True, pad_right=True,\n",
    "                    left_pad_symbol='_', right_pad_symbol='_'))[1:-1]\n",
    "  return [''.join(el) for el in tmp]\n",
    "\n",
    "\n",
    "def word_to_tri_idxs(word):\n",
    "  trigrams = split_trigrams(word)\n",
    "  res_idxs = []\n",
    "  for el in trigrams:\n",
    "    if el not in tri_to_ix:\n",
    "      continue\n",
    "    res_idxs.append(tri_to_ix[el])\n",
    "  return res_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qh8TP7TrK22S"
   },
   "outputs": [],
   "source": [
    "all_known_tokens = [el for el in s if el in wv_embeddings]\n",
    "\n",
    "word_to_idxs= {}\n",
    "tri_to_ix = {}\n",
    "idx = 0\n",
    "\n",
    "for word in all_known_tokens:\n",
    "  if word in word_to_idxs.keys():\n",
    "    continue\n",
    "  \n",
    "  cur_word_idxs = []\n",
    "  \n",
    "  for cur_trigram in split_trigrams(word):\n",
    "    if cur_trigram not in tri_to_ix:\n",
    "      tri_to_ix[cur_trigram] = idx\n",
    "      idx += 1\n",
    "      \n",
    "    cur_word_idxs.append(tri_to_ix[cur_trigram])\n",
    "      \n",
    "  word_to_idxs[word] = cur_word_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IXeGS5-CwbaP"
   },
   "outputs": [],
   "source": [
    "class TrigrammEmbeddingsModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=300):\n",
    "        \"\"\"\n",
    "        all_known_tokens : list of str\n",
    "        \n",
    "        embedding_dim : int\n",
    "        \"\"\"\n",
    "        super(TrigrammEmbeddingsModel, self).__init__()\n",
    "        self.embeddings = nn.EmbeddingBag(vocab_size, embedding_dim, mode='sum')\n",
    "        self.linear1 = nn.Linear(embedding_dim, embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs, torch.LongTensor([0]).cuda()).view((1, -1))\n",
    "        out = self.linear1(embeds)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lp-qC0JqLD-d"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 300\n",
    "\n",
    "losses = []\n",
    "loss_function = nn.MSELoss()\n",
    "model = TrigrammEmbeddingsModel(len(tri_to_ix), EMBEDDING_DIM)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  model.cuda()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "l198KSgjLGAj",
    "outputId": "94781f96-076b-48d9-a75f-e3344fa3663f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 488.4089390216395\n",
      "20 304.48993815714493\n",
      "40 244.50172939291224\n",
      "60 222.10283241514117\n",
      "80 213.8580022919923\n",
      "100 210.82291428628378\n",
      "120 209.51692701270804\n",
      "140 208.75341397710145\n",
      "141 208.79324299027212\n",
      "142 208.7833336351905\n",
      "143 208.7643227588851\n",
      "144 208.8465801558923\n",
      "145 208.6159463126678\n",
      "146 208.72815914452076\n",
      "147 208.56963336584158\n",
      "148 208.67036741273478\n",
      "149 208.68204514717218\n",
      "CPU times: user 41min 47s, sys: 8min 5s, total: 49min 52s\n",
      "Wall time: 50min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for epoch in range(150):\n",
    "  total_loss = 0\n",
    "  for word in all_known_tokens:\n",
    "    context_idxs = torch.tensor(word_to_idxs[word], dtype=torch.long).cuda()\n",
    "\n",
    "    model.zero_grad()\n",
    "\n",
    "    emb = model(context_idxs)\n",
    "\n",
    "    loss = loss_function(emb, torch.tensor([wv_embeddings[word]] , dtype=torch.float).cuda())\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    total_loss += loss.item()\n",
    "  if (epoch%20 == 0) or epoch > 140:\n",
    "    print(epoch, total_loss)\n",
    "  losses.append(total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WM5y61ezLVPw"
   },
   "source": [
    "<font color='blue'>\n",
    "  Проверка модели\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KVFXTDH1LUVn",
    "outputId": "885d71b9-7d54-43e6-a4b6-655aa2b930a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3902028]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'respect'\n",
    "\n",
    "e1 = wv_embeddings[word]\n",
    "\n",
    "tri_idxs = word_to_tri_idxs(word)\n",
    "e2 = model(torch.tensor(tri_idxs, dtype=torch.long).cuda()).cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "cosine_similarity(e1.reshape(1, -1), e2.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vE15qm6ZwbaQ"
   },
   "source": [
    "<font color='red'>** Обучите модель. Оцените, как изменилось качество. Сделайте выводы.**</font>\n",
    "\n",
    "Если вы всё реализовали правильно, качество решения должно вырасти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ol6XsiqxwbaQ"
   },
   "outputs": [],
   "source": [
    "def question_to_vec_by_mean2(question, embeddings, dim=300):\n",
    "    \"\"\"\n",
    "        question: a string\n",
    "        embeddings: dict where the key is a word and a value is its' embedding\n",
    "        dim: size of the representation\n",
    "\n",
    "        result: vector representation for the question\n",
    "    \"\"\"\n",
    "    tokens = word_tokenize(question)\n",
    "\n",
    "    emb = []\n",
    "    for t in tokens:\n",
    "      if t in embeddings:\n",
    "        emb.append(embeddings[t])\n",
    "      else:\n",
    "        tri_idxs = word_to_tri_idxs(t)\n",
    "        emb.append(model(torch.tensor(tri_idxs, dtype=torch.long).cuda()).cpu().detach().numpy().reshape(-1))\n",
    "    \n",
    "    if emb == list():\n",
    "      emb = [np.zeros(dim)]\n",
    "    print(emb)\n",
    "    print(np.mean(emb, axis=0).shape)\n",
    "    return np.mean(emb, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QCqoOkglWSqy"
   },
   "outputs": [],
   "source": [
    "def rank_candidates(question, candidates, embeddings, dim=300):\n",
    "    \"\"\"\n",
    "        question: a string\n",
    "        candidates: a list of strings (candidates) which we want to rank\n",
    "        embeddings: some embeddings\n",
    "        dim: dimension of the current embeddings\n",
    "        \n",
    "        result: a list of pairs (initial position in the list, question)\n",
    "    \"\"\"\n",
    "    question_emb = question_to_vec_by_mean2(question, embeddings, dim)\n",
    "    \n",
    "    return sorted(list(enumerate(candidates)),\n",
    "                  reverse=True,\n",
    "                  key=lambda x: cosine_similarity(\n",
    "                      [\n",
    "                          question_to_vec_by_mean2(x[1],\n",
    "                                                  embeddings,\n",
    "                                                  dim)\n",
    "                      ],\n",
    "                      [question_emb]\n",
    "                  )\n",
    "                 )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2OWbULU2QBDj"
   },
   "outputs": [],
   "source": [
    "dont rerun _next two cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "C-A28E_oLqM9",
    "outputId": "134f3a01-b41f-441d-a524-29c0ae8ff53e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 2min 9s, sys: 1min 29s, total: 1h 3min 38s\n",
      "Wall time: 1h 3min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "wv_ranking = []\n",
    "for idx, line in enumerate(validation):\n",
    "    line = map(text_prepare, line)\n",
    "    q, *ex = line\n",
    "    ranks = rank_candidates(q, ex, wv_embeddings)\n",
    "    wv_ranking.append([r[0] for r in ranks].index(0) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "wnwwguGKLuqw",
    "outputId": "2aefed92-d451-4ec0-ea20-d8a0609e4eb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@   1: 0.428 | Hits@   1: 0.428\n",
      "DCG@   5: 0.500 | Hits@   5: 0.563\n",
      "DCG@  10: 0.515 | Hits@  10: 0.607\n",
      "DCG@ 100: 0.547 | Hits@ 100: 0.770\n",
      "DCG@ 500: 0.565 | Hits@ 500: 0.909\n",
      "DCG@1000: 0.575 | Hits@1000: 1.000\n"
     ]
    }
   ],
   "source": [
    "for k in [1, 5, 10, 100, 500, 1000]:\n",
    "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), k, hits_count(wv_ranking, k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lwwW6Q8JwbaR"
   },
   "source": [
    "## Бонусная часть: векторные представления StarSpace (2 балла)\n",
    "\n",
    "В бонусной части вам предлгается обучить эмбеддинги специально для задачи поиска дубликатов с помощью пакета [StarSpace](https://github.com/facebookresearch/StarSpace). К сожалению, его нельзя запустить на Windows, поэтому в этом случае мы рекоммендуем использовать готовый [docker container](https://github.com/hse-aml/natural-language-processing/blob/master/Docker-tutorial.md) с пошаговыми инструкциями или воспользоваться платформой google colab.\n",
    "\n",
    "Данная модель все еще представляет вопросы с помощью усреднения векторов слов, однако обучается по размеченной выборке пар близких вопросов. Это позволяет обучить вектора, которые лучше подходят для конкретной задачи. Напомним, что в модели word2vec обучение происходят по парам близких слов, и на этапе обучения модель ничего не знает о наших планах по их усреднению в пост-обработке.\n",
    "\n",
    "\n",
    "### Как выбрать  параметры модели?\n",
    "\n",
    "Ниже приведены некоторые рекомендации, с которых можно начать свои эксперименты.\n",
    "\n",
    "- Обучение на парах близких предложений соответствует режиму *trainMode = 3*.\n",
    "- Используйте метод оптимизации adagrad (параметр *adagrad=True*).\n",
    "- Установите длину фразы равной 1 (параметр *ngrams*), чтобы получить только вектора слов.\n",
    "- Не используйте большое количество эпох (5 должно быть достаточно).\n",
    "- Поэкспериментируйте с несколькими размерностями *dim* (например, от 100 до 300).\n",
    "- Для сравнения векторов используйте *косинусную меру*.\n",
    "- Установите *minCount* больше 1 (например, 2), если вы не хотите получить вектора для редко встречающихся слов.\n",
    "- Параметр *verbose=True* будет показывать вам прогресс процесса обучения.\n",
    "- Параметр *negSearchLimit* отвечает за число отрицательных примеров, которые используются в обучении, рекомендованное значение 10.\n",
    "- Для ускорения обучения мы рекоммендуем поставить *шаг обучения (learning rate)* равным 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hxOdNuDiwbaR"
   },
   "source": [
    "<font color='red'>** Обучите вектора StarSpace для униграм на обучающей выборке. Не забудьте использовать предобработанную версию данных. **</font>\n",
    "\n",
    "Если вы следовали инструкциям правильно, то процесс обучения займет около 1 часа. Размер словаря полученных векторных представлений должен быть порядка 100000 (число строк в полученном файле). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "gyfPV-6_wbaR",
    "outputId": "7311266e-fc7c-484d-bea7-03af71874a2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hello world'"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def text_prepare(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified string\n",
    "    \"\"\"\n",
    "    # to lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    # punct -> ' '\n",
    "    punct = string.punctuation\n",
    "    text = text.translate(str.maketrans(punct, ' '*len(punct)))\n",
    "    \n",
    "    \n",
    "    # removing stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words.add('')\n",
    "    text = [w for w in text.split() if w not in stop_words]\n",
    "    \n",
    "    return ' '.join(text)\n",
    "    \n",
    "text_prepare('Hello World?()+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "UvdiC47id2GV",
    "outputId": "f2db0dd9-831b-4668-a742-36d393c7cdf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min, sys: 14.7 s, total: 3min 14s\n",
      "Wall time: 3min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "output_path = 'train_preproc.tsv'\n",
    "\n",
    "out = open(output_path, 'w+')\n",
    "\n",
    "idx = 0\n",
    "\n",
    "with open(train_path) as fp:\n",
    "  line = fp.readline()\n",
    "  while line:\n",
    "    idx += 1\n",
    "    t1, t2, *_ = line.split('\\t')\n",
    "    t1 = text_prepare(t1)\n",
    "    t2 = text_prepare(t2)\n",
    "    print('\\t'.join([t1,t2]), file=out)\n",
    "    line = fp.readline()\n",
    "\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "id": "nVhgq-51eWV2",
    "outputId": "41ba0f21-af4e-46b2-e278-058313a27d2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Starspace'...\n",
      "remote: Enumerating objects: 861, done.\u001b[K\n",
      "remote: Total 861 (delta 0), reused 0 (delta 0), pack-reused 861\u001b[K\n",
      "Receiving objects: 100% (861/861), 2.96 MiB | 5.11 MiB/s, done.\n",
      "Resolving deltas: 100% (562/562), done.\n",
      "g++ -pthread -std=gnu++11 -O3 -funroll-loops -g -c src/utils/normalize.cpp\n",
      "g++ -pthread -std=gnu++11 -O3 -funroll-loops -I/usr/local/bin/boost_1_63_0/ -g -c src/dict.cpp\n",
      "g++ -pthread -std=gnu++11 -O3 -funroll-loops -g -c src/utils/args.cpp\n",
      "g++ -pthread -std=gnu++11 -O3 -funroll-loops -I/usr/local/bin/boost_1_63_0/ -g -c src/proj.cpp\n",
      "g++ -pthread -std=gnu++11 -O3 -funroll-loops -I/usr/local/bin/boost_1_63_0/ -g -c src/parser.cpp -o parser.o\n",
      "g++ -pthread -std=gnu++11 -O3 -funroll-loops -I/usr/local/bin/boost_1_63_0/ -g -c src/data.cpp -o data.o\n",
      "g++ -pthread -std=gnu++11 -O3 -funroll-loops -I/usr/local/bin/boost_1_63_0/ -g -c src/model.cpp\n",
      "g++ -pthread -std=gnu++11 -O3 -funroll-loops -I/usr/local/bin/boost_1_63_0/ -g -c src/starspace.cpp\n",
      "g++ -pthread -std=gnu++11 -O3 -funroll-loops -I/usr/local/bin/boost_1_63_0/ -g -c src/doc_parser.cpp -o doc_parser.o\n",
      "g++ -pthread -std=gnu++11 -O3 -funroll-loops -I/usr/local/bin/boost_1_63_0/ -g -c src/doc_data.cpp -o doc_data.o\n",
      "g++ -pthread -std=gnu++11 -O3 -funroll-loops -I/usr/local/bin/boost_1_63_0/ -g -c src/utils/utils.cpp -o utils.o\n",
      "g++ -pthread -std=gnu++11 -O3 -funroll-loops normalize.o dict.o args.o proj.o parser.o data.o model.o starspace.o doc_parser.o doc_data.o utils.o -I/usr/local/bin/boost_1_63_0/ -g src/main.cpp -o starspace\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/facebookresearch/Starspace.git\n",
    "!cd Starspace && make\n",
    "!mv Starspace/starspace ../bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 935
    },
    "colab_type": "code",
    "id": "8DUL6ouXeYvC",
    "outputId": "0670177f-0595-4de8-b68f-57a5b77952ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arguments: \n",
      "lr: 0.05\n",
      "dim: 100\n",
      "epoch: 5\n",
      "maxTrainTime: 8640000\n",
      "validationPatience: 10\n",
      "saveEveryEpoch: 0\n",
      "loss: hinge\n",
      "margin: 0.05\n",
      "similarity: cosine\n",
      "maxNegSamples: 10\n",
      "negSearchLimit: 10\n",
      "batchSize: 5\n",
      "thread: 10\n",
      "minCount: 2\n",
      "minCountLabel: 1\n",
      "label: __label__\n",
      "label: __label__\n",
      "ngrams: 1\n",
      "bucket: 2000000\n",
      "adagrad: 1\n",
      "trainMode: 3\n",
      "fileFormat: labelDoc\n",
      "normalizeText: 0\n",
      "dropoutLHS: 0\n",
      "dropoutRHS: 0\n",
      "useWeight: 0\n",
      "weightSep: :\n",
      "Start to initialize starspace model.\n",
      "Build dict from input file : train_preproc.tsv\n",
      "Read 11M words\n",
      "Number of words in dictionary:  65628\n",
      "Number of labels in dictionary: 0\n",
      "Loading data from file : train_preproc.tsv\n",
      "Total number of examples loaded : 999924\n",
      "Initialized model weights. Model size :\n",
      "matrix : 65628 100\n",
      "Training epoch 0: 0.05 0.01\n",
      "Epoch: 100.0%  lr: 0.040060  loss: 0.040871  eta: 0h5m  tot: 0h1m17s  (20.0%)\n",
      " ---+++                Epoch    0 Train error : 0.03998139 +++--- ☃\n",
      "Training epoch 1: 0.04 0.01\n",
      "Epoch: 100.0%  lr: 0.030330  loss: 0.012284  eta: 0h3m  tot: 0h2m29s  (40.0%)\n",
      " ---+++                Epoch    1 Train error : 0.01217938 +++--- ☃\n",
      "Training epoch 2: 0.03 0.01\n",
      "Epoch: 100.0%  lr: 0.020060  loss: 0.008543  eta: 0h2m  tot: 0h3m42s  (60.0%)\n",
      " ---+++                Epoch    2 Train error : 0.00851990 +++--- ☃\n",
      "Training epoch 3: 0.02 0.01\n",
      "Epoch: 100.0%  lr: 0.010120  loss: 0.006844  eta: 0h1m  tot: 0h4m54s  (80.0%)\n",
      " ---+++                Epoch    3 Train error : 0.00687005 +++--- ☃\n",
      "Training epoch 4: 0.01 0.01\n",
      "Epoch: 100.0%  lr: 0.000040  loss: 0.006120  eta: <1min   tot: 0h6m5s  (100.0%)\n",
      " ---+++                Epoch    4 Train error : 0.00609368 +++--- ☃\n",
      "Saving model to file : model.mod\n",
      "Saving model in tsv format : model.mod.tsv\n"
     ]
    }
   ],
   "source": [
    "!starspace train \\\n",
    "-adagrad 1 \\\n",
    "-ngrams 1 \\\n",
    "-epoch 5 \\\n",
    "-dim 100 \\\n",
    "-similarity cosine \\\n",
    "-minCount 2 \\\n",
    "-verbose 1 \\\n",
    "-negSearchLimit 10 \\\n",
    "-lr 0.05 \\\n",
    "--fileFormat labelDoc \\\n",
    "-trainFile 'train_preproc.tsv' \\\n",
    "-trainMode 3 \\\n",
    "-model model.mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bO9DxKTfwbaS"
   },
   "source": [
    "Ниже вы можете проверить качество работы вашей модели. Так как обучение происходило для конкретной задачи на размеченных данных, то ожидается, что это решение будет иметь более высокое качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "GCnJVE-DwbaS",
    "outputId": "54297115-8513-446d-8fd6-bdbe10417d9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "CPU times: user 2.05 s, sys: 173 ms, total: 2.22 s\n",
      "Wall time: 2.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "starspace_embeddings = {}\n",
    "DIM = 100\n",
    "\n",
    "filepath = 'model.mod.tsv'\n",
    "with open(filepath) as fp:\n",
    "  line = fp.readline()\n",
    "  idx = 0\n",
    "  while line:\n",
    "    arr = line.split()\n",
    "    starspace_embeddings[' '.join(list(map(str,line.split()[:-DIM])))] = list(map(float, arr[-DIM:]))\n",
    "    line = fp.readline()\n",
    "    if idx % 10000 == 0:\n",
    "      print(idx)\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mRc7MaU4nsHD"
   },
   "outputs": [],
   "source": [
    "def rank_candidates(question, candidates, embeddings, dim=300):\n",
    "    \"\"\"\n",
    "        question: a string\n",
    "        candidates: a list of strings (candidates) which we want to rank\n",
    "        embeddings: some embeddings\n",
    "        dim: dimension of the current embeddings\n",
    "        \n",
    "        result: a list of pairs (initial position in the list, question)\n",
    "    \"\"\"\n",
    "    question_emb = question_to_vec_by_mean(question, embeddings, dim)\n",
    "    \n",
    "    return sorted(list(enumerate(candidates)),\n",
    "                  reverse=True,\n",
    "                  key=lambda x: cosine_similarity(\n",
    "                      [\n",
    "                          question_to_vec_by_mean(x[1],\n",
    "                                                  embeddings,\n",
    "                                                  dim)\n",
    "                      ],\n",
    "                      [question_emb]\n",
    "                  )\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_MD_OYcvwbaT",
    "outputId": "23084ddb-5476-440c-edaf-c0ce0b810171"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3760/3760 [25:40<00:00,  3.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "ss_prepared_ranking = []\n",
    "for line in tqdm(validation):\n",
    "    line = map(text_prepare, line)\n",
    "    q, *ex = line\n",
    "    ranks = rank_candidates(q, ex, starspace_embeddings, dim=DIM)\n",
    "    ss_prepared_ranking.append([r[0] for r in ranks].index(0) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "Nl4Fown9wbaT",
    "outputId": "4d8ac107-54c0-46c4-dbaa-3e691a16b3cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@   1: 0.542 | Hits@   1: 0.542\n",
      "DCG@   5: 0.636 | Hits@   5: 0.715\n",
      "DCG@  10: 0.657 | Hits@  10: 0.780\n",
      "DCG@ 100: 0.686 | Hits@ 100: 0.920\n",
      "DCG@ 500: 0.695 | Hits@ 500: 0.985\n",
      "DCG@1000: 0.696 | Hits@1000: 1.000\n"
     ]
    }
   ],
   "source": [
    "for k in [1, 5, 10, 100, 500, 1000]:\n",
    "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(ss_prepared_ranking, k), \n",
    "                                              k, hits_count(ss_prepared_ranking, k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t8wjGLVQIYx2"
   },
   "outputs": [],
   "source": [
    "## dim=100 | ~60k words | removed all but letters\n",
    "DCG@   1: 0.542 | Hits@   1: 0.542\n",
    "DCG@   5: 0.636 | Hits@   5: 0.716\n",
    "DCG@  10: 0.655 | Hits@  10: 0.774\n",
    "DCG@ 100: 0.684 | Hits@ 100: 0.919\n",
    "DCG@ 500: 0.693 | Hits@ 500: 0.984\n",
    "DCG@1000: 0.694 | Hits@1000: 1.000\n",
    "    \n",
    "## dim=300 | ~60k words | removed all but letters\n",
    "DCG@   1: 0.544 | Hits@   1: 0.544\n",
    "DCG@   5: 0.644 | Hits@   5: 0.727\n",
    "DCG@  10: 0.663 | Hits@  10: 0.786\n",
    "DCG@ 100: 0.691 | Hits@ 100: 0.923\n",
    "DCG@ 500: 0.700 | Hits@ 500: 0.985\n",
    "DCG@1000: 0.701 | Hits@1000: 1.000\n",
    "    \n",
    "## dim=100 | ~65.5k words | removed string.punctuation\n",
    "DCG@   1: 0.549 | Hits@   1: 0.549\n",
    "DCG@   5: 0.639 | Hits@   5: 0.715\n",
    "DCG@  10: 0.658 | Hits@  10: 0.776\n",
    "DCG@ 100: 0.689 | Hits@ 100: 0.920\n",
    "DCG@ 500: 0.697 | Hits@ 500: 0.985\n",
    "DCG@1000: 0.699 | Hits@1000: 1.000\n",
    "    \n",
    "## dim=300 | ~65.5k words | removed string.punctuation\n",
    "DCG@   1: 0.551 | Hits@   1: 0.551\n",
    "DCG@   5: 0.644 | Hits@   5: 0.723\n",
    "DCG@  10: 0.662 | Hits@  10: 0.778\n",
    "DCG@ 100: 0.691 | Hits@ 100: 0.920\n",
    "DCG@ 500: 0.699 | Hits@ 500: 0.984\n",
    "DCG@1000: 0.701 | Hits@1000: 1.000\n",
    "    \n",
    "## dim=100 | ~82k words | removed '!\"#%\\'*,-./:;<=>?@\\\\^_`{|}~'\n",
    "DCG@   1: 0.536 | Hits@   1: 0.536\n",
    "DCG@   5: 0.632 | Hits@   5: 0.715\n",
    "DCG@  10: 0.650 | Hits@  10: 0.769\n",
    "DCG@ 100: 0.681 | Hits@ 100: 0.918\n",
    "DCG@ 500: 0.690 | Hits@ 500: 0.984\n",
    "DCG@1000: 0.692 | Hits@1000: 1.000\n",
    "    \n",
    "## dim=300 | ~82k words | removed '!\"#%\\'*,-./:;<=>?@\\\\^_`{|}~'\n",
    "DCG@   1: 0.549 | Hits@   1: 0.549\n",
    "DCG@   5: 0.641 | Hits@   5: 0.720\n",
    "DCG@  10: 0.661 | Hits@  10: 0.780\n",
    "DCG@ 100: 0.690 | Hits@ 100: 0.920\n",
    "DCG@ 500: 0.698 | Hits@ 500: 0.985\n",
    "DCG@1000: 0.700 | Hits@1000: 1.000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HU6SYBViwbaU"
   },
   "source": [
    "<font color='red'>**Опишите результаты ваших экспериментов, сделайте выводы.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XIQa1MCKId45"
   },
   "source": [
    "В этом практическом задании необходимо было найти похожий вопрос в списке вопросов. \n",
    "\n",
    "В первой части \"сырые\" предложения были переведены в word2vec по словно и усреднены, все неизвестные слова пропускались.\n",
    "\n",
    "Во второй части данные были \"грубо\" предобработаны, а именно были удалены все небуквенные символы. Качество улучшилось. Это работает лучше, так как не отбрасываются слова, содержащие большие буквы или какие-то другие символы. Под \"грубой\" предобработкой понимается удаления всего кроме букв, такой подход был выбран так как в  эмбедингах не было популярных слов содержащих символы.\n",
    "\n",
    "В третьей части неизвестные слова были представлены суммой триграмм и переведены в word2vec. Модель, переводящая триграммы в word2vec была обучена самостоятельно, на основе уже обученных векторов. Качество улучшилось, относительно второй части, так как большинство неизвестных слов не пропускается, а переводятся в word2vec.\n",
    "\n",
    "В бонусной части модель word2vec была обучена самостоятельно, что положительно сказалось на качестве, оно улучшилось относительно третьей части. Это произошло благодаря тому, что модель word2vec была обучена на той же выборке, из которой и приходят тестовые обьекты, это всегда положительно сказывается на качестве, если обучающая выборка достаточна для обучения модели.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "lab_word_embeddings(clear).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
