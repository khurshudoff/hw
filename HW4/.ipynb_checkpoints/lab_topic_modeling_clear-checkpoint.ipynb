{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практическое задание 4 \n",
    "\n",
    "# Мультиязычный тематический поиск\n",
    "\n",
    "## курс \"Математические методы анализа текстов\"\n",
    "\n",
    "\n",
    "### ФИО: <впишите>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение\n",
    "\n",
    "### Постановка задачи:\n",
    "\n",
    "В этом задании вам предстоит сделать свою небольшую мультиязычную поисковую систему. Проще всего строить мультиязычные системы, имея \"параллельные\" данные: словари или корпуса параллельных текстов. \n",
    "\n",
    "В задании необходимо, имея англо-русскую и агло-испанскую коллекции, обучить модель поиска модель поиска испанских текстов по русским.\n",
    "\n",
    "Решение этого задания будет основано на тематическом моделировании, а именно подходе аддитивной регуляризации.\n",
    "\n",
    "### Библиотеки\n",
    "\n",
    "Для этого задания вам понадобятся следующие библиотеки:\n",
    " - [bigartm](http://bigartm.org/)\n",
    " - [pymorphy2](https://pymorphy2.readthedocs.io/en/latest/)\n",
    " - [nltk](http://www.nltk.org/)\n",
    "\n",
    "\n",
    "### Данные\n",
    "\n",
    "Данные — записи выступлений конференции TED Talks на трёх языках. \n",
    "\n",
    "Все данные содержатся в архиве `ted_collection`. В папке содержится три подпапки `/en`, `/ru` и `/es`, каждая из которых соответствует коллекции для отдельного языка. Папка `parallel_info`  содержит информацию о связях документов между коллекциями. Файл `titles_file.json` содержит информацию о заголовках документов английской коллекции.\n",
    "\n",
    "Ссылка для скачивания данных: [ссылка на гугл диск](https://drive.google.com/file/d/1B3kDfISvWnVpEet_CDa6oLNp028mEak-/view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Импорт важных библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# считывание\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "\n",
    "# предобработка\n",
    "import pymystem3\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "# тематическое моделирование\n",
    "import artm\n",
    "\n",
    "# change log style for artm\n",
    "lc = artm.messages.ConfigureLoggingArgs()\n",
    "lc.minloglevel = 3\n",
    "lib = artm.wrapper.LibArtm(logging_config=lc)\n",
    "\n",
    "# визуализация\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# прочее \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Несколько важных промежуточных функций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка коллекции\n",
    "from lab4_utils import load_collection\n",
    "\n",
    "# загрузка информации о параллельных документах\n",
    "from lab4_utils import load_parallel_documents_info\n",
    "\n",
    "# запись vowpal wabit файла специального формата\n",
    "from lab4_utils import write_vw_lab4\n",
    "\n",
    "# подсчёт позиции в выдаче переводов текстов\n",
    "from lab4_utils import get_indexes_of_relevant_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных (3 балла)\n",
    "\n",
    "Перед тем как начать моделировать, необходимо предобработать данные. \n",
    "\n",
    "Заметим, что для английского языка некоторые этапы обработки не оказывают сильного влияния на модель (например, лемматизация). В русском языке одному слову может соответствовать огромное количество различных форм, поэтому без лемматизации невозможно получить модель с хорошим качеством."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Предобработка русских текстов\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считываем коллекцию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of documents: 2731\n",
      "\n",
      "Some document examples: \n",
      "\t10 марта 2011 года я был в Кембридже в MIT Media Lab на встрече с профессорами, студентами и персона...\n",
      "\tПоследние 10 лет я провёл, пытаясь понять, как и почему люди объединяются в социальные сети. Социаль...\n",
      "\tКое-что в физике не давало мне покоя с самого детства. Речь идёт о вопросе, которым учёные задаются ...\n",
      "\t26 января 2013 года боевики «Аль-Каиды» ворвались в древний город Тимбукту на юге Сахары. Они подожг...\n",
      "\tВам знакомо расхожее мнение, что защита климата – занятие дорогое, иначе проблема была бы давно реше...\n",
      "\n",
      "Some file names examples: \n",
      "\tru_2334\n",
      "\tru_1783\n",
      "\tru_2106\n",
      "\tru_927\n",
      "\tru_2562\n"
     ]
    }
   ],
   "source": [
    "RU_DATA_PATH = 'ted_collection/ru'\n",
    "ru_collection = load_collection(RU_DATA_PATH, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведите полностью несколько документов. Подумайте, какую информацию из них можно удалить на этапе предобработки, не ухудшив качество решения задачи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ru_delete_trash(text):\n",
    "#     delete (Аплодисменты)\n",
    "    text = text.replace(\"(Аплодисменты)\", \"\")\n",
    "    \n",
    "#     remove last eng symbols\n",
    "    text = text[:text.rfind(\"TED.com\")]\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помимо удаления специфичной информации, вам необходимо провести для русского языка следующие шаги предобработки :\n",
    "\n",
    "1. Приведение документов к нижнему регистру.\n",
    "\n",
    "2. Удаление всех символов кроме букв.\n",
    "    1. Для некоторых способов выделения коллокаций (см. бонусную часть), может быть полезна информация о знаках препинания. Также она полезна при необходимости строить синтаксический разбор предложения.\n",
    "    2. Вам может помочь функция sub из библиотеки re.\n",
    "3. Токенизация документов.\n",
    "    1. Воспользуйтесь стандартным методом .split, функцией split из библиотеки re или одним из токенайзеров библиотеки nltk.\n",
    "4. Лемматизация документов.\n",
    "    1. Воспользуйтесь библиотекой pymorphy2\n",
    "    2. Шаги 3 и 4 можно выполнить вместе, воспользовавшись библиотекой mytem (или её обёрткой на python pymystem)\n",
    "5. Удаление стоп-слов\n",
    "    1. Базовый список стоп слов можно получить из модуля nltk.corpus\n",
    "\n",
    "После выполнения всех шагов сохраните результат в словарь аналогичный ru_collection (ключи - названия файлов, значения - предобработанный документ в формате str).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pymystem3.Mystem()\n",
    "STOPWORDS_ru = nltk.corpus.stopwords.words('russian') + [' ', '\\n']\n",
    "\n",
    "def preprocess_ru(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w ]', ' ', text)\n",
    "    text = re.sub(r'\\d_', '', text)\n",
    "    text = re.sub(r'[\\s]+', ' ', text)\n",
    "    text = m.lemmatize(text)\n",
    "    text = [word for word in text if word not in STOPWORDS_ru]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_ru_collection = {}\n",
    "for key in list(ru_collection.keys()):\n",
    "    preprocessed_ru_collection[key] = preprocess_ru(ru_delete_trash(ru_collection[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проанализируйте несколько предобработанных документов. Отметьте, какие неточности работы алгоритмов вы заметили, и как они могут повлиять на итоговую модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторые стопслова не содержаться в nltk.corpus, например 'это'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Предобработка английских текстов\n",
    "\n",
    "Считываем коллекцию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of documents: 2856\n",
      "\n",
      "Some document examples: \n",
      "\tToday, I want you to look at children who become suicide bombers through a completely different lens...\n",
      "\tI have a very difficult task. I'm a spectroscopist. I have to talk about astronomy without showing y...\n",
      "\tI really am honored to be here, and as Chris said, it's been over 20 years since I started working i...\n",
      "\tThirteen years ago, we set ourselves a goal to end poverty. After some success, we've hit a big hurd...\n",
      "\tOne thing the world needs, one thing this country desperately needs is a better way of conducting ou...\n",
      "\n",
      "Some file names examples: \n",
      "\ten_495\n",
      "\ten_1635\n",
      "\ten_2282\n",
      "\ten_1407\n",
      "\ten_1063\n"
     ]
    }
   ],
   "source": [
    "EN_DATA_PATH = 'ted_collection/en'\n",
    "en_collection = load_collection(EN_DATA_PATH, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведите все этапы предобработки для английского языка (шаг 4 опционален, можно использовать WordNetLemmatizer из nltk):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS_en = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def en_delete_trash(text):\n",
    "#     delete (Аплодисменты)\n",
    "    text = text.replace(\"(Applause)\", \"\")\n",
    "    \n",
    "#     remove last eng symbols\n",
    "    text = text[:text.rfind(\"TED.com\")]\n",
    "    return text\n",
    "\n",
    "def preprocess_en(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w ]', ' ', text)\n",
    "    text = re.sub(r'\\d_', '', text)\n",
    "    text = re.sub(r'[\\s]+', ' ', text)\n",
    "    text = text.split(\" \")\n",
    "    text = [word for word in text if word not in STOPWORDS_en]\n",
    "    return text\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_en_collection = {}\n",
    "for key in list(en_collection.keys()):\n",
    "    preprocessed_en_collection[key] = preprocess_en(en_delete_trash(en_collection[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Предобработка испанских текстов \n",
    "\n",
    "Считываем коллекцию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of documents: 2809\n",
      "\n",
      "Some document examples: \n",
      "\tEra mi tercer día de trabajo en una empresa emergente en Silicon Valley a principios de 2013. Tenía ...\n",
      "\tEstamos en un momento crítico. Nuestros líderes, algunas de nuestras grandes instituciones nos están...\n",
      "\tEste es el museo de Historia Natural de Rotterdam, donde trabajo como curador. Cuido la colección y ...\n",
      "\tChris Anderson: Vamos a tener un debate. El debate es sobre la propuesta: \"Lo que el mundo necesita ...\n",
      "\tSoy microbióloga oceanográfica en la Universidad de Tennessee, y quiero hablarles sobre algunos micr...\n",
      "\n",
      "Some file names examples: \n",
      "\tes_1801\n",
      "\tes_309\n",
      "\tes_907\n",
      "\tes_1459\n",
      "\tes_2826\n"
     ]
    }
   ],
   "source": [
    "ES_DATA_PATH = 'ted_collection/es'\n",
    "es_collection = load_collection(ES_DATA_PATH, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведите все этапы предобработки для испанского языка (шаг 4 опционален, можно использовать SpanishStemmer из nltk). \n",
    "\n",
    "**Замечание.** Регулярное выражение \\w из библиотеки re позволяет выделять буквы (в том числе буквы испанского алфавита)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS_es = nltk.corpus.stopwords.words('spanish')\n",
    "st = nltk.stem.snowball.SpanishStemmer()\n",
    "\n",
    "def es_delete_trash(text):\n",
    "#     delete (Аплодисменты)\n",
    "    text = text.replace(\"(Aplausos)\", \"\")\n",
    "    \n",
    "#     remove last esp symbols\n",
    "    text = text[:text.rfind(\"TED.com\")]\n",
    "    return text\n",
    "\n",
    "def preprocess_es(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w ]', ' ', text)\n",
    "    text = re.sub(r'\\d_', '', text)\n",
    "    text = re.sub(r'[\\s]+', ' ', text)\n",
    "    text = text.split(\" \")\n",
    "    text = [st.stem(word) for word in text if word not in STOPWORDS_es]\n",
    "    return text\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_es_collection = {}\n",
    "for key in list(es_collection.keys()):\n",
    "    preprocessed_es_collection[key] = preprocess_es(es_delete_trash(es_collection[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Дополнительная предобработка\n",
    "\n",
    "Библиотека BigARTM имеет собственный формат документов для обработки, называемый батчами. Самый простой способ создать батчи из коллекции файлов - сконвертировать в батчи vowpal wabbit файл с коллекцией (https://github.com/VowpalWabbit/vowpal_wabbit/wiki/Input-format). \n",
    "\n",
    "Тематические модели работают с мешком слов, поэтому в vowpal wabbit файле можно не хранить информацию о порядке слов в документе.\n",
    "\n",
    "Чтобы обучить мультиязычную модель, мы будем использовать апарат модальностей тематической модели. Каждому языку будет соответствовать своя модальность (`@english`, `@russian` и `@spanish` в vowpal wabbit файле). \n",
    "\n",
    "Для экспериментов нам понадобится два файла. Один будет содержать информацию о параллельных документов, а другой нет. В втором файле каждая строчка соответствует конкретному документу. В первом файле, если у документа есть параллельный, он будет располагаться на этой же строчке в рамках другой модальности.\n",
    "\n",
    "Весь код для сохранения файла в vowpal wabbit формате уже написан, вам только необходимо правильно воспользоваться функцией. В частности, проследите, чтобы в ваших документах не содержалось символов ':', '|' и '@'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В файлах en_ru_match.txt и en_es_match.txt содержится информация о том, какие документы являются параллельными. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of pairs: 1000\n",
      "Total number of pairs: 1000\n"
     ]
    }
   ],
   "source": [
    "en_ru_parallel_docs = load_parallel_documents_info('ted_collection/parallel_info/en_ru_match.txt')\n",
    "en_es_parallel_docs = load_parallel_documents_info('ted_collection/parallel_info/en_es_match.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуйтесь функцией write_vw_lab4, чтобы сохранить данные в нужном формате:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vowpal wabbit файлы с коллекцией\n",
    "DATA_PATH_PARALLEL = 'ted_collection/collection_parallel.vw'\n",
    "DATA_PATH_MONO = 'ted_collection/collection_mono.vw'\n",
    "\n",
    "write_vw_lab4(\n",
    "    DATA_PATH_PARALLEL,\n",
    "    preprocessed_en_collection,\n",
    "    preprocessed_ru_collection,\n",
    "    preprocessed_es_collection,\n",
    "    en_ru_parallel_docs,\n",
    "    en_es_parallel_docs,\n",
    "    use_parallel_info=True\n",
    ")\n",
    "\n",
    "\n",
    "write_vw_lab4(\n",
    "    DATA_PATH_MONO,\n",
    "    preprocessed_en_collection,\n",
    "    preprocessed_ru_collection,\n",
    "    preprocessed_es_collection,\n",
    "    en_ru_parallel_docs,\n",
    "    en_es_parallel_docs,\n",
    "    use_parallel_info=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Базовая моноязычная тематическая модель (2 балла)\n",
    "\n",
    "Теорию тематического моделирования можно узнать из лекций [9](http://www.machinelearning.ru/wiki/images/7/79/Mmta2018-artm-1.pdf) и [10](http://www.machinelearning.ru/wiki/images/a/ab/Mmta2018-artm-2.pdf).\n",
    "\n",
    "Научиться пользоваться bigartm легче всего по гайду из документации [ссылка](http://docs.bigartm.org/en/stable/tutorials/python_userguide/index.html).\n",
    "\n",
    "#### Подготовка к моделированию\n",
    "\n",
    "Чтобы преобразовать полученный vowpal wabbit файл в батчи, можно воспользоваться стандартным классом BatchVectorizer. Объект этого класса принимает на вход адрес папки с батчами или файл vowpal wabbit, а затем подаётся на вход для обучения методам. В случае, если входные данные не являются батчами, он создаёт их и сохраняет на диск для последующего быстрого использования.\n",
    "\n",
    "В этой части экспериментов, вам предлагается построить моноязычную тематическую модель только для английского языка, поэтому для обучения используйте файл DATA_PATH_MONO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# папка с батчами\n",
    "BATCHES_PATH_MONO = 'ted_collection/batch_mono'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# если BATCHES_PATH_MONO пуста, батчи будут созданы из файла в DATA_PATH_MONO\n",
    "# иначе использовать BATCHES_PATH_MONO\n",
    "if len(glob.glob(os.path.join(BATCHES_PATH_MONO + '/*.batch'))) < 1:\n",
    "    batch_vectorizer_mono = artm.BatchVectorizer(data_path=DATA_PATH_MONO, \n",
    "                                                 data_format='vowpal_wabbit',\n",
    "                                                 target_folder=BATCHES_PATH_MONO)\n",
    "else:\n",
    "    batch_vectorizer_mono = artm.BatchVectorizer(data_path=BATCHES_PATH_MONO,\n",
    "                                                 data_format='batches')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Словарь – это объект BigARTM, содержащий информацию о коллекции (словарь коллекции, различные величины и счётчики, связанные со словами). Создать словарь можно на основе папки с батчами. Затем собранный словарь можно сохранять на диск и позже подгрузить вновь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = artm.Dictionary()\n",
    "dictionary.gather(data_path=BATCHES_PATH_MONO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Словарь в том числе отвечает за то, на какие токены будет настраиваться модель. Редкие слова не оказывают влияние на модель, поэтому их можно удалить используя метод .filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artm.Dictionary(name=411ebdd0-6d06-43a0-b078-9cd5cc5f9ca6, num_entries=54032)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MIN_DF = 5\n",
    "\n",
    "dictionary.filter(min_df=MIN_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение модели\n",
    "\n",
    "Пришло время приступить к моделированию! Начнём с простой одноязычной модели PLSA. Будем учитывать только модальность @english в документах коллекции. Так как коллекция небольшая, используйте небольшое число тем 30-50.\n",
    "\n",
    "Параметр theta_columns_naming='title' отвечает за именование документов лейблами из vowpal wabbit формата при получении матрицы $\\Theta$ (иначе они будут нумероваться в порядке появления в коллекции)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = artm.ARTM(num_topics=30,\n",
    "                  num_processors=7,\n",
    "                  theta_columns_naming='title',\n",
    "                  class_ids={'@english':1})\n",
    "\n",
    "model.initialize(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс artm.ARTM поддерживает различные встроенные метрики качества. Добавьте метрики измерения перплексии, разреженности $\\Phi$, разреженности $\\Theta$ и счётчик топ слов. Не забудьте, что метрики должны соответствовать только модальности @english!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.scores.add(artm.PerplexityScore(name='perplexity_score', class_ids=['@english']))\n",
    "model.scores.add(artm.SparsityPhiScore(name='sparsity_phi_score', class_id='@english'))\n",
    "model.scores.add(artm.SparsityThetaScore(name='sparsity_theta_score'))\n",
    "model.scores.add(artm.TopTokensScore(name='top_tokens_score', class_id='@english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведите обучение модели с помощью метода fit_offline. Подберите необходимое число операций для сходимости в зависимости от значения перплексии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_offline(batch_vectorizer_mono, num_collection_passes=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведите график изменения перплексии в зависимости от итерации алгоритма, чтобы мы знали, что ваш алгоритм точно сошёлся :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x140bcf6d8>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(model.score_tracker['perplexity_score'].value[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1456526d8>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(model.score_tracker['sparsity_phi_score'].value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Интерпретация результатов\n",
    "\n",
    "Основная особенность тематических моделей — интерпретируемость получаемых матриц $\\Phi$ и $\\Theta$. С помощью $\\Phi$ для каждой темы можно узнать топ-слова, а с помощью $\\Theta$ для каждой темы можно узнать топ-документы. \n",
    "Для того, чтобы получить матрицу $\\Theta$, используйте метод .transform.\n",
    "\n",
    "Для каждой темы выведите топ её слов ($\\geq 20$) и топ заголовкой её документов ($\\geq 5$). Попробуйте интерпертировать полученные темы, действительно ли темы получаются осмысленными?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_to_title = {}\n",
    "with open('ted_collection/titles_file.json') as f:\n",
    "    for line in f:\n",
    "        file_name_to_title.update(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DOCS\n",
    "theta = model.transform(batch_vectorizer_mono)\n",
    "\n",
    "topic2top_docs = {}\n",
    "for row_name, row in theta.iterrows():\n",
    "    topic2top_docs[row_name] = [file_name_to_title[el] for el in list(row.sort_values(ascending=False)[:5].index)]\n",
    "    \n",
    "    \n",
    "## WORDS\n",
    "phi = model.get_phi()\n",
    "\n",
    "topic2top_words = {}\n",
    "for row_name, row in phi.T.iterrows():\n",
    "    topic2top_words[row_name] = list(row.sort_values(ascending=False)[:5].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtopic_0 WORDS: \u001b[0m\n",
      "women, men, woman, girls, sex, \n",
      "\u001b[31mtopic_0 DOCS TITLES: \u001b[0m\n",
      "Sofia Jawed-Wessel: The lies we tell pregnant women\n",
      "Peggy Orenstein: What young women believe about their own sexual pleasure\n",
      "Frans de Waal: The surprising science of alpha males\n",
      "Jackson Katz: Violence against women -- it's a men's issue\n",
      "Chimamanda Ngozi Adichie: We should all be feminists\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001b[31mtopic_1 WORDS: \u001b[0m\n",
      "life, day, would, one, years, \n",
      "\u001b[31mtopic_1 DOCS TITLES: \u001b[0m\n",
      "Tan Le: My immigration story\n",
      "Hyeonseo Lee: My escape from North Korea\n",
      "Melissa Fleming: A boat carrying 500 refugees sunk at sea. The story of two survivors\n",
      "Tania Luna: How a penny made me feel like a millionaire\n",
      "Joseph Kim: The family I lost in North Korea. And the family I gained.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001b[31mtopic_2 WORDS: \u001b[0m\n",
      "government, information, people, us, internet, \n",
      "\u001b[31mtopic_2 DOCS TITLES: \u001b[0m\n",
      "Trevor Timm: How free is our freedom of the press?\n",
      "Mikko Hypponen: Three types of online attack\n",
      "Mikko Hypponen: How the NSA betrayed the world's trust -- time to act\n",
      "Laura Galante: How (and why) Russia hacked the US election\n",
      "Christopher Soghoian: How to avoid surveillance ... with the phone in your pocket\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001b[31mtopic_3 WORDS: \u001b[0m\n",
      "laughter, like, know, right, going, \n",
      "\u001b[31mtopic_3 DOCS TITLES: \u001b[0m\n",
      "Lennart Green: Close-up card magic with a twist\n",
      "Arthur Benjamin: A performance of \"Mathemagic\"\n",
      "TED staff: It's TED, the Musical\n",
      "Raspyni Brothers: Juggle and jest\n",
      "Helder Guimarães: A magical search for a coincidence\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001b[31mtopic_4 WORDS: \u001b[0m\n",
      "said, went, know, laughter, got, \n",
      "\u001b[31mtopic_4 DOCS TITLES: \u001b[0m\n",
      "Nancy Frates: Meet the mom who started the Ice Bucket Challenge\n",
      "Benjamin Wallace: The price of happiness\n",
      "Bill Strickland: Rebuilding a neighborhood with beauty, dignity, hope\n",
      "Malcolm Gladwell: Choice, happiness and spaghetti sauce\n",
      "Jia Jiang: What I learned from 100 days of rejection\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for key in list(topic2top_words.keys())[:5]:\n",
    "\n",
    "    print(\"\\x1b[31m\" + key + \" WORDS: \\x1b[0m\")\n",
    "    for el in [el[1][1:-2] for el in topic2top_words[key]]:\n",
    "        print(el, end=', ')\n",
    "    print()\n",
    "    print(\"\\x1b[31m\" + key + \" DOCS TITLES: \\x1b[0m\")\n",
    "    for el in topic2top_docs[key]:\n",
    "        print(el)\n",
    "    print('-' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часто, топ 5 слов достаточно что бы понять смысл темы. Однако, иногда их бывает недостаточно. В таких случаях трудно понять смысл темы, как видно в topic_1, topic_22. Но в этом случае помогают названия документов.\n",
    "\n",
    "В topic_10 и topic_12 в топ 5 слов попало слово us, которое почему-то не состоит в стоп-словах, его стоит туда добавить.\n",
    "\n",
    "Возможно, стоит уменьшить число тем, так как темы некоторых документов достаточно похожи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Мультиязычная тематическая модель (5 баллов)\n",
    "\n",
    "В этом пункте задания вам будет необходимо обучить мультиязычную тематическую модель.\n",
    "\n",
    "В данном пункте вы будете реализовывать модель ML-TD (MultiLingual Parallel).\n",
    "\n",
    "* каждый язык — отдельная модальность\n",
    "* $\\theta_{td}$ — общая для всех параллельных документов\n",
    "\n",
    "Таким образом на обучении все параллельные документы записываются в одну строку в vowpal wabbit файле.\n",
    "\n",
    "Оценивать качество модели мы будем на задаче поиска перевода текста. Вам будет необходимо оценить качество трёх переводов: с русского на английский, с испанского на английский и с русского на испанский.\n",
    "\n",
    "Поиск документов будет устроен следующим образом. Будем для документа d на языке A считать близости со всеми документами на языке B и ранжировать документы языка B по этой близости. Для каждого документа посчитаем позицию истинного перевода документа в выдаче. Итоговая метрика — медиана или среднее таких позиций по всем документам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим множества документов, для которых не было известно информации об их переводе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_es_parallel_docs_test = load_parallel_documents_info('ted_collection/parallel_info/ru_es_match_test.txt', verbose=False)\n",
    "ru_en_parallel_docs_test = load_parallel_documents_info('ted_collection/parallel_info/ru_en_match_test.txt', verbose=False)\n",
    "es_en_parallel_docs_test = load_parallel_documents_info('ted_collection/parallel_info/es_en_match_test.txt', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведите подготовительный этап (создание батчей и словарей) для мультиязычной коллекции DATA_PATH_PARALLEL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# папка с батчами\n",
    "BATCHES_PATH_PARALLEL = 'ted_collection/batch_parallel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# если BATCHES_PATH_MONO пуста, батчи будут созданы из файла в DATA_PATH_PARALLEL\n",
    "# иначе использовать BATCHES_PATH_MONO\n",
    "if len(glob.glob(os.path.join(BATCHES_PATH_PARALLEL + '/*.batch'))) < 1:\n",
    "    batch_vectorizer_parallel = artm.BatchVectorizer(data_path=DATA_PATH_PARALLEL, \n",
    "                                                 data_format='vowpal_wabbit',\n",
    "                                                 target_folder=BATCHES_PATH_PARALLEL)\n",
    "else:\n",
    "    batch_vectorizer_parallel = artm.BatchVectorizer(data_path=BATCHES_PATH_PARALLEL,\n",
    "                                                 data_format='batches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = artm.Dictionary()\n",
    "dictionary.gather(data_path=BATCHES_PATH_PARALLEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artm.Dictionary(name=d8d17106-e133-4880-a6ba-0cc50463582a, num_entries=54032)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MIN_DF = 5\n",
    "\n",
    "dictionary.filter(min_df=MIN_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите мультиязычную модель и проинтерпертируйте полученные темы. Если вы всё сделали правильно, то топ-слова различных языков для одной темы должны получиться достаточно похожими."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :\n",
      "4.0 49.535\n",
      "19.0 102.125\n",
      "1.0 37.4675\n",
      "--------------------\n",
      "1 :\n",
      "1.0 22.315\n",
      "2.0 30.70375\n",
      "0.0 8.45375\n",
      "--------------------\n",
      "2 :\n",
      "0.0 12.72\n",
      "1.0 14.42875\n",
      "0.0 3.37875\n",
      "--------------------\n",
      "3 :\n",
      "0.0 8.4625\n",
      "0.0 9.87\n",
      "0.0 3.22625\n",
      "--------------------\n",
      "4 :\n",
      "0.0 7.1375\n",
      "0.0 8.38\n",
      "0.0 3.65\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "kf_es, kf_en, kf_ru = 0.35, 0.9, 0.50\n",
    "\n",
    "model = artm.ARTM(num_topics=16,\n",
    "                  num_processors=-1,\n",
    "                  theta_columns_naming='title',\n",
    "                  class_ids={'@english': kf_en, '@spanish': kf_es, '@russian': kf_ru})\n",
    "\n",
    "model.initialize(dictionary)\n",
    "\n",
    "for it in range(5):\n",
    "    model.fit_offline(batch_vectorizer_parallel, num_collection_passes=40)\n",
    "\n",
    "    idxs__ru_en, _ = get_indexes_of_relevant_documents(model.transform(batch_vectorizer_mono),\n",
    "                                                       ru_en_parallel_docs_test)\n",
    "    idxs__ru_es, _ = get_indexes_of_relevant_documents(model.transform(batch_vectorizer_mono),\n",
    "                                                       ru_es_parallel_docs_test)\n",
    "    idxs__es_en, _ = get_indexes_of_relevant_documents(model.transform(batch_vectorizer_mono),\n",
    "                                                       es_en_parallel_docs_test)\n",
    "    print(it, ':')\n",
    "    print(np.median(idxs__ru_en), np.mean(idxs__ru_en))\n",
    "    print(np.median(idxs__ru_es), np.mean(idxs__ru_es))\n",
    "    print(np.median(idxs__es_en), np.mean(idxs__es_en))\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируйте качество на трёх задачах перевода. Добейтесь хорошего качества (медиана позиции в выдаче ~ 0, среднее ~ 10). Получить положение в выдаче переводов текстов вам поможет функция get_indexes_of_relevant_documents из модуля lab4_utils. Для того, чтобы всё работало корректно (на тесте не должна быть известна информация о параллельности документов), подавайте в качестве theta результат model.transform(batch_vectorizer_mono).\n",
    "\n",
    "Возможные способы улучшения:\n",
    "* изменять количество тем, количество итераций обучения\n",
    "* изменять веса модальностей\n",
    "* добавлять регуляризаторы (см. бонусную часть)\n",
    "* изменять метрику для поиска ближайших документов\n",
    "* добавлять шаги в предобработку (выделение колокаций)\n",
    "\n",
    "За нетривиальные подходы могут быть начислены дополнительные бонусные баллы!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 7.1375\n",
      "0.0 8.38\n",
      "0.0 3.65\n"
     ]
    }
   ],
   "source": [
    "tmp = get_indexes_of_relevant_documents(model.transform(batch_vectorizer_mono), ru_en_parallel_docs_test)\n",
    "print(np.median(tmp[0]), np.mean(tmp[0]))\n",
    "\n",
    "tmp = get_indexes_of_relevant_documents(model.transform(batch_vectorizer_mono), ru_es_parallel_docs_test)\n",
    "print(np.median(tmp[0]), np.mean(tmp[0]))\n",
    "\n",
    "tmp = get_indexes_of_relevant_documents(model.transform(batch_vectorizer_mono), es_en_parallel_docs_test)\n",
    "print(np.median(tmp[0]), np.mean(tmp[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведите анализ ошибок. На каких документах модель отработала лучше всего, на каких хуже всего? Как вы думаете почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = model.transform(batch_vectorizer_mono)\n",
    "parallel_docs = ru_en_parallel_docs_test\n",
    "metric = 'cosine'\n",
    "\n",
    "theta_T = theta.T\n",
    "embeddigns_norms = (theta_T ** 2).sum(axis=1) ** 0.5\n",
    "\n",
    "one_language_relevant_docs, _ = zip(*parallel_docs.items())\n",
    "one_language_relevant_docs = list(one_language_relevant_docs)\n",
    "one_language_relevant_embeddings = (\n",
    "    theta_T\n",
    "    .loc[one_language_relevant_docs]\n",
    ")\n",
    "one_language_relevant_norms = (\n",
    "    embeddigns_norms\n",
    "    .loc[one_language_relevant_docs]\n",
    ")\n",
    "\n",
    "second_language_example = next(iter(parallel_docs.values()))\n",
    "second_language_docs = [\n",
    "    document\n",
    "    for document in theta_T.index\n",
    "    if document[:2] == second_language_example[:2]\n",
    "]\n",
    "second_language_embeddings = theta_T.loc[second_language_docs]\n",
    "second_language_norms = embeddigns_norms.loc[second_language_docs]\n",
    "\n",
    "similarity_matrix = (\n",
    "    one_language_relevant_embeddings\n",
    "    .dot(second_language_embeddings.T)\n",
    ")\n",
    "\n",
    "if metric == 'cosine':\n",
    "    similarity_matrix = similarity_matrix.div(one_language_relevant_norms, axis='index')\n",
    "    similarity_matrix = similarity_matrix.div(second_language_norms, axis='columns')\n",
    "\n",
    "similarity_matrix_array = similarity_matrix.values\n",
    "estimations = similarity_matrix_array.argsort(axis=1)[:, ::-1]\n",
    "second_lang_doc_to_number = dict(zip(similarity_matrix.columns,\n",
    "                                     range(len(similarity_matrix.columns))))\n",
    "\n",
    "result_index = []\n",
    "docs_pair = []\n",
    "\n",
    "for i, one_document in enumerate(similarity_matrix.index):\n",
    "    if parallel_docs[one_document] not in similarity_matrix.columns:\n",
    "        continue\n",
    "    doc_index = second_lang_doc_to_number[\n",
    "        parallel_docs[one_document]\n",
    "    ]\n",
    "    index_in_output = np.where(estimations[i] == doc_index)[0]\n",
    "    result_index.append(index_in_output[0])\n",
    "    docs_pair.append((one_document, parallel_docs[one_document]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11225.8325"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(ru_collection[i]) for i in similarity_matrix.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ = []\n",
    "\n",
    "for i, el in enumerate(result_index):\n",
    "    if el > 0:\n",
    "        all_.append(len(ru_collection[similarity_matrix.index[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10503.84879725086"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Одной из самых сложных задач в компьютерной графике было создание фото-реалистичного цифрового лица человека. Одна из причин, почему это так сложно сделать, в отличие от инопланетян или динозавров, заключается в том, что мы видим человеческие лица каждый день. Они очень важны для нас при общении друг с другом. В результате мы обращаем внимание на мельчайшие детали, с которыми может быть что-то не так при компьютерном воспроизведении, для того чтобы поверить, что эти детали выглядят реалистично.\\nВ течение следующих 5 минут я объясню вам процесс, в ходе которого мы попытались создать на компьютере достаточно фото-реалистичное лицо с помощью разработанной нами технологии компьютерной графики, а также нескольких коллег из компании Image Metrics. Мы постараемся воссоздать фото-реалистичное лицо актрисы Эмили О' Брайен. Вот она. Это действительно полностью созданное на компьютере изображение её лица. В конце презентации мы увидим, как оно движется.\\nИтак, мы начали с самой Эмили, которая любе\""
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 1\n",
    "\n",
    "one_document = similarity_matrix.index[i]\n",
    "ru_collection[one_document][:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Никаких закономерностей между текстами на которых совершается ошибка и текстами, которые находятся правильно замечено не было. Длина текстов, на которых совершается ошибка незначительно меньше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бонусная часть\n",
    "\n",
    "#### Добавление фоновых тем (до 1 балла)\n",
    "\n",
    "Основной инструмент улучшения качества тематической модели — регуляризация. Выделите часть тем модели как фоновые. Сглаживайте $\\Theta$ для фоновых тем, разреживайте для предметных.\n",
    "\n",
    "Проинтерпретируйте результаты. Фоновые темы должны иметь в качество топ-слов слова фоновой лексики! Удалось ли с помощью введения фоновых тем повысить качество модели?\n",
    "\n",
    "#### Модальность n-грамм (до 2 баллов)\n",
    "\n",
    "Для каждого языка добавьте дополнительную модальность n-грамм. n-граммы можно выделить, например, с помощью пакета Phrases из модуля Gensim. Как отразилось добавление новой модальности на интерпретируемости модели? Удалось ли с помощью введения n-грамм повысить качество модели?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.6",
   "language": "python",
   "name": "other-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
